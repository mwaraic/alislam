{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdsMOBaBfyT0"
      },
      "source": [
        "##### Copyright 2025 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "rIIf_RgOf3sr"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TySweisNf_Am"
      },
      "source": [
        "# Gemini API: Question Answering using LangChain and Pinecone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awKO767lQIWh"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/examples/langchain/Gemini_LangChain_QA_Pinecone_WebLoad.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" height=30/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bA5Hys5PU_nt"
      },
      "source": [
        "## Overview\n",
        "\n",
        "[Gemini](https://ai.google.dev/models/gemini) is a family of generative AI models that lets developers generate content and solve problems. These models are designed and trained to handle both text and images as input.\n",
        "\n",
        "[LangChain](https://www.langchain.com/) is a data framework designed to make integration of Large Language Models (LLM) like Gemini easier for applications.\n",
        "\n",
        "[Pinecone](https://www.pinecone.io/) is a cloud-first vector database that allows users to search across billions of embeddings with ultra-low query latency.\n",
        "\n",
        "In this notebook, you'll learn how to create an application that answers questions using data from a website with the help of Gemini, LangChain, and Pinecone."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qRjVe1tZhsx"
      },
      "source": [
        "## Setup\n",
        "\n",
        "First, you must install the packages and set the necessary environment variables.\n",
        "\n",
        "### Installation\n",
        "\n",
        "Install LangChain's Python library, `langchain` and LangChain's integration package for Gemini, `langchain-google-genai`. Next, install LangChain's integration package for the new version of Pinecone, `langchain-pinecone` and the `pinecone-client`, which is Pinecone's Python SDK. Finally, install `langchain-community` to access the `WebBaseLoader` module later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olK4Ejjzuj76"
      },
      "outputs": [],
      "source": [
        "%pip install --quiet langchain-core\n",
        "%pip install --quiet langchain\n",
        "%pip install --quiet langchain-google-genai\n",
        "%pip install --quiet -U langchain-community\n",
        "%pip install --quiet pinecone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQOGMejVu-6D"
      },
      "source": [
        "## Configure your API key\n",
        "\n",
        "To run the following cell, your API key must be stored in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see [Authentication](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb) for an example.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ysayz8skEfBW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "GOOGLE_API_KEY=os.environ.get('GOOGLE_API_KEY')\n",
        "# COHERE_API_KEY=os.environ.get('COHERE_API_KEY')\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "# os.environ[\"COHERE_API_KEY\"] = COHERE_API_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPQLjFvRooqn"
      },
      "source": [
        "### Setup Pinecone\n",
        "\n",
        "To use Pinecone in your application, you must have an API key. To create an API key you have to set up a Pinecone account. Visit [Pinecone's app page](https://app.pinecone.io/), and Sign up/Log in to your account. Then navigate to the \"API Keys\" section and copy your API key.\n",
        "\n",
        "For more detailed instructions on getting the API key, you can read Pinecone's [Quickstart documentation](https://docs.pinecone.io/docs/quickstart#2-get-your-api-key).\n",
        "\n",
        "Set the environment variable `PINECONE_API_KEY` to configure Pinecone to use your API key.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "A7jTZLEApgtm"
      },
      "outputs": [],
      "source": [
        "PINECONE_API_KEY=os.environ.get('PINECONE_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGOKV3XflBCe"
      },
      "source": [
        "## Basic steps\n",
        "LLMs are trained offline on a large corpus of public data. Hence they cannot answer questions based on custom or private data accurately without additional context.\n",
        "\n",
        "If you want to make use of LLMs to answer questions based on private data, you have to provide the relevant documents as context alongside your prompt. This approach is called Retrieval Augmented Generation (RAG).\n",
        "\n",
        "You will use this approach to create a question-answering assistant using the Gemini text model integrated through LangChain. The assistant is expected to answer questions about Gemini model. To make this possible you will add more context to the assistant using data from a website.\n",
        "\n",
        "In this tutorial, you'll implement the two main components in an RAG-based architecture:\n",
        "\n",
        "1. Retriever\n",
        "\n",
        "    Based on the user's query, the retriever retrieves relevant snippets that add context from the document. In this tutorial, the document is the website data.\n",
        "    The relevant snippets are passed as context to the next stage - \"Generator\".\n",
        "\n",
        "2. Generator\n",
        "\n",
        "    The relevant snippets from the website data are passed to the LLM along with the user's query to generate accurate answers.\n",
        "\n",
        "You'll learn more about these stages in the upcoming sections while implementing the application."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPhs4mDkjdgY"
      },
      "source": [
        "## Import the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TcvGPVdXu05F"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
            "/Users/mwaraich/alislam/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from langchain import hub\n",
        "from langchain import PromptTemplate\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.schema import StrOutputParser\n",
        "from langchain.schema.prompt_template import format_document\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "from pinecone import PodSpec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZ3tM0T2lbVm"
      },
      "source": [
        "## Retriever\n",
        "\n",
        "In this stage, you will perform the following steps:\n",
        "\n",
        "1. Read and parse the website data using LangChain.\n",
        "\n",
        "2. Create embeddings of the website data.\n",
        "\n",
        "    Embeddings are numerical representations (vectors) of text. Hence, text with similar meaning will have similar embedding vectors. You'll make use of Gemini's embedding model to create the embedding vectors of the website data.\n",
        "\n",
        "3. Store the embeddings in Pinecone's vector store.\n",
        "    \n",
        "    Pinecone is a vector database. The Pinecone vector store helps in the efficient retrieval of similar vectors. Thus, for adding context to the prompt for the LLM, relevant embeddings of the text matching the user's question can be retrieved easily using Pinecone.\n",
        "\n",
        "4. Create a Retriever from the Pinecone vector store.\n",
        "\n",
        "    The retriever will be used to pass relevant website embeddings to the LLM along with user queries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2N-NCPElqN3"
      },
      "source": [
        "### Read and parse the website data\n",
        "\n",
        "LangChain provides a wide variety of document loaders. To read the website data as a document, you will use the `WebBaseLoader` from LangChain.\n",
        "\n",
        "To know more about how to read and parse input data from different sources using the document loaders of LangChain, read LangChain's [document loaders guide](https://python.langchain.com/docs/integrations/document_loaders)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8NXNTrjp0jdh"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "gemini_embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-exp-03-07\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr5xeWUXmnUe"
      },
      "source": [
        "### Store the data using Pinecone\n",
        "\n",
        "\n",
        "To create a Pinecone vector database, first, you have to initialize your Pinecone client connection using the API key you set previously.\n",
        "\n",
        "In Pinecone, vector embeddings have to be stored in indexes. An index represents the vector data's top-level organizational unit. The vectors in any index must have the same dimensionality and distance metric for calculating similarity. You can read more about indexes in [Pinecone's Indexes documentation](https://docs.pinecone.io/docs/indexes).\n",
        "\n",
        "First, you'll create an index using Pinecone's `create_index` function. Pinecone allows you to create two types of indexes, Serverless indexes and Pod-based indexes. Pinecone's free starter plan lets you create only one project and one pod-based starter index with sufficient resources to support 100,000 vectors. For this tutorial, you have to create a pod-based starter index. To know more about different indexes and how they can be created, read Pinecone's [create indexes guide](https://docs.pinecone.io/docs/new-api#creating-indexes).\n",
        "\n",
        "\n",
        "Next, you'll insert the documents you extracted earlier from the website data into the newly created index using LangChain's `Pinecone.from_documents`. Under the hood, this function creates embeddings from the documents created by the document loader of LangChain using any specified embedding model and inserts them into the specified index in a Pinecone vector database.  \n",
        "\n",
        "You have to specify the `docs` you created from the website data using LangChain's `WebBasedLoader` and the `gemini_embeddings` as the embedding model when invoking the `from_documents` function to create the vector database from the website data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "n1VwhUQMvpcN"
      },
      "outputs": [],
      "source": [
        "from pinecone import Pinecone as pc\n",
        "\n",
        "# Initialize Pinecone client\n",
        "pine_client = pc(api_key=\"pcsk_3NGhRC_2Eg2DzYQKdYXBv1ReHB6EYoBjsKCoCzm5BJe1HeKH8LRbm3CdL6h6bmasJna9vo\")\n",
        "index_name = \"seerat-ul-mahdi\"\n",
        "index = pine_client.Index(index_name, \"https://seerat-ul-mahdi-vm3wi2f.svc.aped-4627-b74a.pinecone.io\")\n",
        "vectorstore = PineconeVectorStore(\n",
        "    index=index,\n",
        "    embedding=gemini_embeddings\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "from time import sleep\n",
        "\n",
        "book_id = \"1342-12463\"\n",
        "\n",
        "for i in range(8, 437):\n",
        "    url = f\"https://new.alislam.org/api/books/text?id={book_id}&pages={i}\"\n",
        "    response = requests.get(url)\n",
        "    text = response.json()[0][\"content\"]\n",
        "    page_number = response.json()[0][\"printPageNum\"]\n",
        "    sleep(1)\n",
        "    vectorstore.add_documents([Document(page_content=text, metadata={\"chunk_index\": i, \"volume\": 1, \"title\": \"seerat-ul-mahdi\", \"page\": page_number})])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuSjapvHnc6T"
      },
      "source": [
        "### Create a retriever using Pinecone\n",
        "\n",
        "You'll now create a retriever that can retrieve website data embeddings from the newly created Pinecone vector store. This retriever can be later used to pass embeddings that provide more context to the LLM for answering user's queries.\n",
        "\n",
        "Invoke the `as_retriever` function of the vector store you initialized in the last step, to create a retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n"
          ]
        }
      ],
      "source": [
        "\n",
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
        "# Check if the retriever is working by trying to fetch the relevant docs related\n",
        "# to the word 'MMLU'(Massive Multitask Language Understanding). If the length is\n",
        "# greater than zero, it means that the retriever is functioning well.\n",
        "print(len(retriever.invoke(\"mufti muhammad sadiq\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Qw00lvPnjfR"
      },
      "source": [
        "## Generator\n",
        "\n",
        "The Generator prompts the LLM for an answer when the user asks a question. The retriever you created in the previous stage from the Pinecone vector store will be used to pass relevant embeddings from the website data to the LLM to provide more context to the user's query.\n",
        "\n",
        "You'll perform the following steps in this stage:\n",
        "\n",
        "1. Chain together the following:\n",
        "    * A prompt for extracting the relevant embeddings using the retriever.\n",
        "    * A prompt for answering any question using LangChain.\n",
        "    * An LLM model from Gemini for prompting.\n",
        "    \n",
        "2. Run the created chain with a question as input to prompt the model for an answer.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2MK2wLwnkLg"
      },
      "source": [
        "### Initialize Gemini\n",
        "\n",
        "You must import `ChatGoogleGenerativeAI` from LangChain to initialize your model.\n",
        " In this example, you will use **gemini-2.0-flash**, as it supports text summarization. To know more about the text model, read Google AI's [language documentation](https://ai.google.dev/models/gemini).\n",
        "\n",
        "You can configure the model parameters such as ***temperature*** or ***top_p***,  by passing the appropriate values when initializing the `ChatGoogleGenerativeAI` LLM.  To learn more about the parameters and their uses, read Google AI's [concepts guide](https://ai.google.dev/docs/concepts#model_parameters)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "CaA1vRCh7s36"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# To configure model parameters use the `generation_config` parameter.\n",
        "# eg. generation_config = {\"temperature\": 0.7, \"topP\": 0.8, \"topK\": 40}\n",
        "# If you only want to set a custom temperature for the model use the\n",
        "# \"temperature\" parameter directly.\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-preview-05-20\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BeLN6RXnuS2"
      },
      "source": [
        "### Create prompt templates\n",
        "\n",
        "You'll use LangChain's [PromptTemplate](https://python.langchain.com/docs/how_to/#prompt-templates) to generate prompts to the LLM for answering questions.\n",
        "\n",
        "In the `llm_prompt`, the variable `question` will be replaced later by the input question, and the variable `context` will be replaced by the relevant text from the website retrieved from the Pinecone vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "90Czqh074dEC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_variables=['book', 'question'] input_types={} partial_variables={} template='You are an Ahmadi scholar who writes counter arguments against Non-Ahmadi scholars.\\nUse the following books to write arguments.\\nAdd reference to the sources of the argument.\\n\\nQuestion: {question}\\nBooks: {book}\\nAnswer:'\n"
          ]
        }
      ],
      "source": [
        "# Prompt template to query Gemini\n",
        "llm_prompt_template = \"\"\"You are an Ahmadi scholar who writes counter arguments against Non-Ahmadi scholars.\n",
        "Use the following books of the Promised Messiah A.S to write counter arguments.\n",
        "Add references to the sources of the argument for example: Ruhani Khazain Vol. X Pg. X\n",
        "\n",
        "Question: {question}\n",
        "Books: {book}\n",
        "Answer:\"\"\"\n",
        "\n",
        "llm_prompt = PromptTemplate.from_template(llm_prompt_template)\n",
        "\n",
        "print(llm_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_variables=['book', 'question'] input_types={} partial_variables={} template='You are an Ahmadi scholar who answer general questions.\\nUse the following books of to answer questions.\\nAdd references to the sources of the answer for example: Ruhani Khazain Vol. X Pg. X, Seerat ul Mahdi Pg. X\\n\\nQuestion: {question}\\nBooks: {book}\\nAnswer:'\n"
          ]
        }
      ],
      "source": [
        "# Prompt template to query Gemini\n",
        "llm_prompt_template = \"\"\"You are an Ahmadi scholar who answer general questions.\n",
        "Use the following books of to answer questions.\n",
        "Add references to the sources of the answer for example: Ruhani Khazain Vol. X Pg. X, Seerat ul Mahdi Vol. XPg. X\n",
        "\n",
        "Question: {question}\n",
        "Books: {book}\n",
        "Answer:\"\"\"\n",
        "\n",
        "llm_prompt = PromptTemplate.from_template(llm_prompt_template)\n",
        "\n",
        "print(llm_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkWpzMmpnx7b"
      },
      "source": [
        "### Create a stuff documents chain\n",
        "\n",
        "LangChain provides [Chains](https://python.langchain.com/docs/modules/chains/) for chaining together LLMs with each other or other components for complex applications. You will create a **stuff documents chain** for this application. A stuff documents chain lets you combine all the relevant documents, insert them into the prompt, and pass that prompt to the LLM.\n",
        "\n",
        "You can create a stuff documents chain using the [LangChain Expression Language (LCEL)](https://python.langchain.com/docs/expression_language).\n",
        "\n",
        "To learn more about different types of document chains, read LangChain's [chains guide](https://python.langchain.com/docs/modules/chains/document/).\n",
        "\n",
        "The stuff documents chain for this application retrieves the relevant website data and passes it as the context to an LLM prompt along with the input question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "gj5sWzpwp7vc"
      },
      "outputs": [],
      "source": [
        "# Combine data from documents to readable string format.\n",
        "def format_docs(docs):\n",
        "    print(docs)\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "# Create stuff documents chain using LCEL.\n",
        "# This is called a chain because you are chaining\n",
        "# together different elements with the LLM.\n",
        "# In the following example, to create a stuff chain,\n",
        "# you will combine content, prompt, LLM model, and\n",
        "# output parser together like a chain using LCEL.\n",
        "#\n",
        "# The chain implements the following pipeline:\n",
        "# 1. Extract data from documents and save to the variable `context`.\n",
        "# 2. Use the `RunnablePassthrough` option to provide question during invoke.\n",
        "# 3. The `context` and `question` are then passed to the prompt and\n",
        "#    input variables in the prompt are populated.\n",
        "# 4. The prompt is then passed to the LLM (`gemini-2.0-flash`).\n",
        "# 5. Output from the LLM is passed through an output parser\n",
        "#    to structure the model response.\n",
        "rag_chain = (\n",
        "    {\"book\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | llm_prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmHx_F7DoMgM"
      },
      "source": [
        "### Prompt the model\n",
        "\n",
        "You can now query the LLM by passing any question to the `invoke()` function of the stuff documents chain you created previously."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "95W-sbTjoGGj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Document(id='3ea5823b-757e-4b00-91eb-98ed6a319ecd', metadata={'chunk_index': 9.0, 'page': 110.0, 'title': 'اِزالہ اوھام', 'volume': '۳'}, page_content='روحانی خزائن ۔ کمپیوٹرائزڈوہ الفاظ بیان نہیں فرمائے جو اس عاجز نے بزعم ان کے اپنی تالیفات میں استعمال کئے ہیں اور درحقیقت سب و شتم میں داخل ہیں۔میں سچ سچ کہتا ہوں کہ جہاں تک مجھے معلوم ہے میں نے ایک لفظ بھی ایسا استعمال نہیں کیا جس کو دشنام دہی کہا جائے بڑے دھوکہ کی با ت یہ ہے کہ اکثر لوگ دشنام دہی اور بیان واقعہ کو ایک ہی صورت میں سمجھ لیتے ہیں اور ان دونوں مختلف مفہوموں میں فرق کرنا نہیں جانتے بلکہ ایسی ہریک بات کو جو دراصل ایک واقعی امر کا اظہار ہو اور اپنے محل پر چسپاں ہو محض اس کی کسی قدر مرارت کی وجہ سے جو حق گوئی کے لازم حال ہوا کرتی ہے دشنام ہی تصور کر لیتے ہیں حالانکہ دشنام اور سب اور شتم فقط اس مفہوم کا نام ہے جو خلاف واقعہ اور دروغ کے طور پر محض آزار رسانی کی غرض سے استعمال کیا جائے اور اگر ہریک سخت اور آزار دہ تقریر کو محض بوجہ اس کے مرارت اور تلخی اور ایذارسانی کے دشنام کے مفہوم میں داخل کر سکتے ہیں تو پھر اقرار کرنا پڑے گا کہ سارا قرآن ؔ شریف گالیوں سے پُر ہے کیونکہ جو کچھ بتوں کی ذلت اور ُ بت پرستوں کی حقارت اور ان کے بارہ میں *** ملامت کے سخت الفاظ قرآن شریف میں استعمال کئے گئے ہیں یہ ہرگز ایسے نہیں ہیں جن کے سننے سے بت پرستوں کے دل خوش ہوئے ہوں بلکہ بلاشبہ ان الفاظ نے ان کے غصہ کی حالت کی بہت تحریک کی ہو گی۔کیا خدائے تعالیٰ کا کفار مکہ کو مخاطب کرکے یہ فرمانا کہاِنَّكُمْ وَمَا تَعْبُدُوْنَ مِنْ دُوْنِ اللّٰهِ حَصَبُ جَهَـنَّمَ  ۱\\u0602   معترض کے من گھڑت قاعدہ کے موافق گالی میں داخل نہیں ہے کیا خدائے تعالیٰ کا قرآن شریف میں کفار کو شَرُّالْبَرِیَّۃ قرار دینا اور تمام رذیل اور پلید مخلوقات سے انہیں بد تر ظاہر کرنا یہ معترض کے خیال کے روسے دشنام دہی میں داخل نہیں ہوگا؟کیاخدائے تعالیٰ نے قرآن شریف میں وَاغْلُظْ عَلَيْهِمْ\\tْ ۲\\u0602 نہیں فرمایا کیا مومنوں کی علامات میںاَشِدَّآءُ عَلَى الْكُفَّارِ ۳\\u0602 نہیں رکھا گیا کیا حضرت مسیح کا یہودیوں کے معزز فقیہوں اور فریسیوں کو سؤر اور کتے کے نام سے پکارنا اور گلیل کے عالی مرتبہ فرمانروا ہیرودیس کا لونبڑی نام ؔ رکھنا اور معزز سردار کاہنوں اور فقیہوں کو۱\\u0602 الانبیاء: ۹۹  ۲\\u0602 التوبۃ:۷۳\\t    ۳\\u0602 الفتح:۳۰Ruhani Khazain Volume 3. Page: 110'), Document(id='7227b892-b9c6-468f-b1f1-809d7f1a0a76', metadata={'chunk_index': 15.0, 'page': 116.0, 'title': 'اِزالہ اوھام', 'volume': '۳'}, page_content='http://www.alislam.org/library/brow...in_Computerised/?l=Urdu&p=3#page/115/mode/1upجس قدر مشرکین کا کینہ ترقی کر گیاتھا اس کا اصل باعث وہ سخت الفاظ ہی تھے جو اُن نادانوں نے دشنام دہی کی صورت پرسمجھ لئے تھے جن کی وجہ سے آخر لسان سے سنان تک نوبت پہنچی ورنہ اول حال تو وہ لوگ ایسے نہیں تھے بلکہ کمال اعتقاؔ د سے آنحضرت صلی اللہ علیہ وسلم کی نسبت کہا کرتے تھے کہ عَشِقَ مُحَمَّدٌ عَلیٰ رَبِّہٖ ۔ یعنی محمد صلی اللہ علیہ وسلم اپنے رب پر عاشق ہو گئے ہیں جیسے آج کل کے ہندو لوگ بھی کسی گوشہ نشین فقیر کو ہرگز بُرا نہیں کہتے بلکہ نذریں نیازیں دیتے ہیں۔اس جگہ مجھے نہایت افسوس اور غمگین دل کے ساتھ اس بات کے ظاہر کرنے کی بھی حاجت پڑی ہے کہ یہ اعتراض جو مجھ پر گیا ہے یہ صرف عوام الناس کی طرف سے ہی نہیں بلکہ میں نے سنا ہے کہ بانی مبانی اس اعتراض کے بعض علماء بھی ہیں۔سو میں ان کی شان میں یہ تو ظن نہیں کر سکتاکہ وہ قرآن شریف اور کتب سابقہ سے بے خبر ہیں اور نہ کسی طور سے جائے ظن ہے * لیکن ؔ میں جانتاہوں کہ آج کل کی یورپ کی جھوٹی تہذیب نےقرآؔ ن شریف جس آوازبلند سے سخت زبانی کے طریق کواستعمال کر رہا ہے ایک غایت درجہ کا غبی اور سخت درجہ کا نادان بھی اُس سے بے خبر نہیں رہ سکتا۔ مثلًا زمانہ حال کے مہذبین کے نزدیک کسی پر *** بھیجنا ایک سخت گالی ہے۔ لیکن قرآن شریف کفارؔ کو سُنا سُنا کر ان پر *** بھیجتا ہے جیسا کہ فرماتا ہےاُولٰٓٮِٕكَ عَلَيْهِمْ لَعْنَةُ اللّٰهِ وَالْمَلٰٓٮِٕكَةِ وَالنَّاسِ اَجْمَعِيْنَۙ۱\\u0602 الجزو ۲ سورۃ بقرہ۔\\t خٰلِدِيْنَ فِيْهَاۚاُولٰٓٮِٕكَ يَلْعَنُهُمُ اللّٰهُ وَ يَلْعَنُهُمُ اللّٰعِنُوْنَۙ\\u200f   ۲\\u0602۔\\tالجزو نمبر ۲ایسا ہی ظاہر ہے کہ کسی انسان کو حیوان کہنا بھی ایک قسم کی گالی ہے۔ لیکن قرآن شریف نہ صرف حیوان بلکہ کفار اور منکرین کو دنیا کے تمام حیوانات سے بد تر قرار دیتا ہے جیسا کہ فرماتا ہےاِنَّ شَرَّ الدَّوَآبِّ عِنْدَ اللّٰهِ الَّذِيْنَ كَفَرُوْ\\t\\t   ۳\\u0602۔ ایسا ہی ظاہرہے کہ کسی خاص آدمی کانام لے کر یا اؔ شارہ کے طورپر اس کو نشانہ بنا کر گالی دینا زمانہ حال کیRuhani Khazain Volume 3. Page: 116'), Document(id='9cb3d96b-5a2c-474c-8bc6-ad80d1c20b1d', metadata={'chunk_index': 16.0, 'page': 117.0, 'title': 'اِزالہ اوھام', 'volume': '۳'}, page_content='http://www.alislam.org/library/brow...in_Computerised/?l=Urdu&p=3#page/116/mode/1upجو ایمانی غیّوری سے بہت دُور پڑی ہوئی ہے ہمارے علماء کے دلوں کو بھی کسی قدر دبا لیا ہے۔اس سخت آندھی کے چلنے کی وجہ سے ان کی آنکھوں میں بھی کچھ غبارساپڑگیاہے اور ان کی فطرتی کمزوری اس نزلہ کو قبول کر گئی ہے۔اسی وجہ سے وہ ایسے خیالات پر زور دیتے ہیں جن کا کوئی اصل صحیح حدیث و قرآن میں نہیں پایا جاتا ہاں یورپ کی اخلاقی کتابوں میں تو ضرور پایا جاتا ہے اور اؔ ن اخلاق میں یورپ نے یہاں تک ترقی کی ہے کہ ایک جوان عورت سے ایک نامحرم طالب کی بکلّی دل شکنی مناسب نہیں سمجھی گئی۔مگر کیا قرآن شریف یورپ کے ان اخلاق سے اتفاق رائے کرتا ہے؟ کیا وہ ایسے لوگوں کا نام دیّوث نہیں رکھتا؟ میں ایسے علماء کو محض للہ متنبہ کرتا ہوں کہ وہ ایسی نکتہ چینیاں کرنے اور ایسے خیالات کو دل میں جگہ دینے سے حق اور حق بینی سے بہت دور جاپڑے ہیں اگر وہ مجھ سے لڑنے کو تیار ہوں تو اپنی خشکؔ منطق سے جو چاہیں کہیں لیکن اگر وہ خدائے تعالیٰ سے خوف کر کے کسی قدرسوچیں تو یہ ایسی بات نہیں ہے جو ان کی نظر سے پوشیدہ رہ سکے نیک بختتہذیب کے برخلاف ہے لیکن خدائے تعالیٰ نے قرآن شریف میں بعض کا نام ابو لہب اوربعض کانام کلب اور خنزیر کہا اور ابو جہل تو خود مشہور ہے ایسا ہی ولید (بن) مغیرہ کی نسبت نہایت درجہ کے سخت الفاظ جو بصورت ظاہر گندی گالیاں معلوم ہوتی ہیں استعمال کئے ہیں جیساکہ فرماتا ہےفَلَا تُطِعِ الْمُكَذِّبِيْنَ\\t وَدُّوْا لَوْ تُدْهِنُ فَيُدْهِنُوْنَ   وَلَا تُطِعْ كُلَّ حَلَّافٍ مَّهِيْنٍۙ\\u200fهَمَّازٍ مَّشَّآءٍۢ بِنَمِيْمٍۙ   مَّنَّاعٍ لِّلْخَيْرِ مُعْتَدٍ اَثِيْمٍۙ عُتُلٍّ ۢ بَعْدَ ذٰلِكَ زَنِيْمٍۙ\\u200fسَنَسِمُهٗ عَلَى الْخُـرْطُوْمِ۔۱\\u0602 دیکھوؔ سورہ القلم الجزو نمبر ۲۹۔ یعنی تُو ان مکذّبوں کے کہنے پر مت چل جو بدل اس بات کے آرزو مند ہیں کہ ہمارے معبودوں کو بُرامت کہو اور ہمارے مذہب کی ہجو مت کرو تو پھر ہم بھی تمہارے مذہب کی نسبت ہاں میں ہاں ملاتے رہیں گے اور ان کی چرب زبانی کا خیال مت کر ویہ شخص جو مداہنہ کا خواستگار ہے جھوٹی قسمیں کھانے والااورضعیف الرائے اور ذلیل آدمی ہے دوسروں کے عیب ڈھونڈنے والا اورسخن چینی سے لوگوں میں تفرقہ ڈالنے والاؔ اورنیکی کی\\t\\t    ۱\\u0602 القلم: ۹ تا ۱۷Ruhani Khazain Volume 3. Page: 117')]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'The allegation made by Muhammad Imtiaz against the Promised Messiah, Hazrat Mirza Ghulam Ahmad (peace be upon him), regarding the use of \"bad language\" and the claim that he stated \"all the Quran is full of swears,\" is a grave misrepresentation and a distortion of his words.\\n\\nThe Promised Messiah (peace be upon him) categorically denied using any language that could be termed as \\'abusive\\' or \\'swearing\\' (dushnam-dehi). He clarified that there is a fundamental difference between true abuse and a statement of fact, which many people mistakenly conflate.\\n\\nHe states:\\n\"I truly say that as far as I know, I have not used a single word that can be called abusive. It is a great deception that most people consider abusive language and a statement of fact to be the same, and they do not know how to differentiate between these two distinct concepts. Rather, they consider every such statement, which is actually an expression of a factual matter and relevant to its context, as abuse merely due to some bitterness which is inherent in speaking the truth. Whereas, abuse, vilification, and swearing is only the name for that meaning which is used contrary to facts and falsely, merely for the purpose of causing harm.\"\\n(Ruhani Khazain, Vol. 3, Izala Auham, p. 110)\\n\\nRegarding the specific statement that \"all the Quran is full of swears,\" the Promised Messiah (peace be upon him) did *not* say this as an accusation against the Holy Quran. Rather, he used a rhetorical argument (a *reductio ad absurdum*) to expose the flawed and superficial understanding of \"abuse\" held by his critics. He argued that *if* every harsh or painful statement were to be considered \\'abuse\\' merely due to its bitterness, harshness, or hurtful nature, then one would logically have to concede that the entire Holy Quran would also fall under such a definition, which is an absurd conclusion, thus proving the critics\\' definition of \\'abuse\\' to be incorrect.\\n\\nHe elaborates on this point by providing numerous examples from the Holy Quran and the practice of earlier Prophets:\\n\\n1.  **Quranic Statements about Idolaters and Idols:**\\n    The Promised Messiah (peace be upon him) asks if the Quranic statements regarding the degradation of idols and the contempt for idolaters, and the severe words of admonition used against them, would not be considered \"abuse\" by the critics\\' standard. He questions:\\n    \"Does not Allah Almighty\\'s addressing the disbelievers of Mecca and saying, \\'Are you and what you worship besides Allah, fuel for Hell?\\' (Holy Quran, 21:99) fall under abuse according to the fabricated rule of the objector? Does not Allah Almighty\\'s declaring the disbelievers in the Holy Quran as \\'the worst of creatures\\' (sharru al-bariyyah) and showing them to be worse than all vile and impure creations, fall under abuse according to the objector\\'s view?\"\\n    (Ruhani Khazain, Vol. 3, Izala Auham, p. 110)\\n\\n2.  **Divine Commands for Severity:**\\n    He further points out:\\n    \"Has not Allah Almighty commanded in the Holy Quran, \\'And be harsh with them\\' (waghlaẓ \\'alayhim) (Holy Quran, 9:73)? Has it not been included in the signs of believers that they are \\'severe against the disbelievers\\' (ashiddaa\\'u \\'alal kuffar) (Holy Quran, 48:30)?\"\\n    (Ruhani Khazain, Vol. 3, Izala Auham, p. 110)\\n\\n3.  **Quranic Curses:**\\n    The Promised Messiah (peace be upon him) also highlights that while contemporary civilized people consider cursing a severe form of abuse, the Holy Quran openly curses disbelievers:\\n    \"For example, according to the civilized people of the present age, to curse someone is a severe abuse. But the Holy Quran curses the disbelievers openly, as it says: \\'Upon them is the curse of Allah and of the angels and of all mankind\\' (Holy Quran, 2:162); \\'Allah curses them and those who curse also curse them\\' (Holy Quran, 2:160).\"\\n    (Ruhani Khazain, Vol. 3, Izala Auham, p. 115)\\n\\n4.  **Calling People Animals:**\\n    He continues:\\n    \"Similarly, it is clear that calling a human being an animal is also a type of abuse. But the Holy Quran not only calls disbelievers and deniers animals, but declares them worse than all animals of the world, as it says: \\'Verily, the worst of beasts in the sight of Allah are those who disbelieve\\' (Holy Quran, 8:56).\"\\n    (Ruhani Khazain, Vol. 3, Izala Auham, p. 115)\\n\\n5.  **Naming and Specific Descriptions of Opponents:**\\n    The Promised Messiah (peace be upon him) points out that the Holy Quran even named specific individuals and used very harsh descriptions for them:\\n    \"Similarly, it is clear that to abuse a specific person by name or by indication is against the present age\\'s civilization. But Allah Almighty in the Holy Quran called some by the name of Abu Lahab and some by the name of dog (Kalab) and pig (Khanzeer), and Abu Jahl is himself famous. Similarly, regarding Walid bin Mughira, extremely harsh words have been used which outwardly appear to be filthy abuses, as it says: \\'So yield not to the disbelievers, who wish that thou shouldst compromise, so that they too might compromise. And yield not to every contemptible swearer of oaths, a slanderer, going about with calumnies, a hinderer of good, a transgressor, a sinner, cruel, besides all that, of doubtful birth. We shall brand him on the snout.\\' (Holy Quran, 68:9-17).\"\\n    (Ruhani Khazain, Vol. 3, Izala Auham, p. 116-117)\\n\\n6.  **Example of Prophet Jesus (peace be upon him):**\\n    He also cites the example of Prophet Jesus (peace be upon him) who used strong language against his opponents:\\n    \"Did not حضرت مسیح (peace be upon him) call the respected Jewish scribes and Pharisees \\'swine\\' and \\'dogs,\\' and name the high-ranking ruler of Galilee, Herod, a \\'fox\\'?\"\\n    (Ruhani Khazain, Vol. 3, Izala Auham, p. 110)\\n\\nThe Promised Messiah (peace be upon him) attributed this faulty understanding of \"abuse\" among some \\'ulama\\' to the influence of \"Europe\\'s false civilization\" (یورپ کی جھوٹی تہذیب) and its \"dry logic\" (خشک منطق), which he believed had somewhat suppressed their natural Islamic zeal and understanding of the Quran and Hadith. He admonished them to fear God and reflect on these matters rather than succumbing to external, un-Islamic ethical standards.\\n\\nIn conclusion, the Promised Messiah (peace be upon him) did not claim that the Holy Quran is \"full of swears\" in a literal or derogatory sense. Instead, he used this strong rhetorical device to demonstrate that if his critics\\' definition of \"abuse\" were consistently applied, it would lead to the absurd conclusion that even the Holy Quran, which uses strong language against falsehood and evil, would be deemed \"abusive.\" His aim was to defend the truth and the necessary forthrightness in condemning falsehood, just as the Holy Quran and previous Prophets did. His language, therefore, was a statement of fact and a defense of divine truth, not an act of baseless abuse.'"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_chain.invoke(\"\"\"*Argument (Made by Muhammad Imtiaz against MGA): QURAAN IS FULL OF SWEARS\n",
        "Replying to the allegations of using bad language against hindu, christians and muslim opponents, Mirza Ghulam Qadiani says if his language is considered as the abusive language then all the Quraan is full of swears. (NAUZUBILLAH Min Zalik.)\n",
        "Give a response.\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Document(id='8d7d1670-a12c-4a35-b2ef-7ee4a9fcf7e8', metadata={'chunk_index': 79.0, 'page': '73', 'title': 'seerat-ul-mahdi', 'volume': 1.0}, page_content='سیرت المہدی\\n73\\nحصہ اوّل\\nکہنی آپ نے سر کے نیچے بطور تکیہ کے رکھ لی اور دوسری اسی صورت میں سر کے اوپر ڈھانک لی۔میں پاؤں\\nدبانے بیٹھ گیا۔وہ رمضان\\nکا مہینہ تھا اور ستائیس تاریخ تھی اور جمعہ کا دن تھا اس لئے میں دل میں بہت\\nمسرور تھا کہ میرے لئے ایسے مبارک موقعے جمع ہیں۔یعنی حضرت صاحب جیسے مبارک انسان کی خدمت\\nکر رہا ہوں وقت فجر کا ہے جو مبارک وقت ہے مہینہ رمضان کا ہے جو مبارک مہینہ ہے۔تاریخ ستائیس اور\\nجمعہ کا دن ہے اور گزشتہ شب شب قدر تھی کیونکہ میں نے حضرت صاحب سے سنا ہوا تھا کہ جب رمضان کی\\nستائیس تاریخ اور جمعہ مل جاویں تو وہ رات یقیناً شب قدر ہوتی ہے۔میں انہی باتوں کا خیال کر کے دل میں\\nمسرور ہو رہا تھا کہ حضرت صاحب کا بدن یکلخت کانپا اور اس کے بعد حضور نے آہستہ سے اپنے اوپر کی کہنی\\nذرا ہٹا کر میری طرف دیکھا اس وقت میں نے دیکھا کہ حضرت صاحب کی آنکھوں میں آنسو بھرے ہوئے\\nتھے اس کے بعد آپ نے پھر اسی طرح اپنی کہنی رکھ لی۔میں دباتے دباتے حضرت صاحب کی پنڈلی پر آیا\\nتو میں نے دیکھا کہ حضور کے پاؤں پر ٹخنے کے نیچے ایک اٹن یعنی سخت سی جگہ تھی اس پر سرخی کا ایک قطرہ پڑا\\nتھا جو بھی تازہ گرے ہونے کی وجہ سے بستہ تھا۔میں نے اسے دائیں ہاتھ کی شہادت کی انگلی لگا کر دیکھا\\nکہ کیا ہے۔اس پر وہ قطرہ ٹخنے پر بھی پھیل گیا اور میری انگلی پر بھی لگ گیا ، پھر میں نے اسے سونگھا کہ شاید\\nاس میں کچھ خوشبو ہو مگر خوشبو نہیں تھی۔میں نے اسے اس لئے سونگھا تھا کہ اسی وقت میرے دل میں یہ خیال\\nآیا تھا کہ یہ کوئی خدا تعالیٰ کی طرف سے بات ہے اس لئے اس میں کوئی خوشبو ہوگی۔پھر میں دبا تا دباتا\\nپسلیوں کے پاس پہنچا وہاں میں نے اسی سرخی کا ایک اور بڑا قطرہ کرتہ پر دیکھا۔اس کو بھی میں نے ٹولا تو وہ\\nبھی گیلا تھا۔اس وقت پھر مجھے حیرانی سی ہوئی کہ یہ سرخی کہاں سے آگئی ہے۔پھر میں چار پائی سے آہستہ\\nسے اُٹھا کہ حضرت صاحب جاگ نہ اُٹھیں اور پھر اس کا نشان تلاش کرنا چاہا کہ یہ سرخی کہاں سے گری ہے۔بہت چھوٹا سا حجرہ تھا۔چھت میں اردگرد میں نے اس کی خوب تلاش کی مگر خارج میں مجھے اس کا کہیں پتہ\\nنہیں چلا کہ کہاں سے گری ہے۔مجھے یہ بھی خیال آیا کہ کہیں چھت پر کسی چھپکلی کی دم کٹی ہو تو اس کا خون گرا\\nہواس لئے میں نے غور کے ساتھ چھت پر نظر ڈالی مگر اس کا کوئی نشان نہیں پایا۔پھر آخر میں تھک کر بیٹھ گیا\\nلے سے تصحیح مطابق روایت نمبر ۳۱۱'), Document(id='d5498225-6b83-4fb5-994a-52a913900537', metadata={'chunk_index': 80.0, 'page': '74', 'title': 'seerat-ul-mahdi', 'volume': 1.0}, page_content='سیرت المہدی\\n74\\nحصہ اوّل\\nاور بدستور دبانے لگ گیا۔تھوڑی دیر کے بعد حضرت صاحب اُٹھ کر بیٹھ گئے اور پھر حجرہ میں سے نکل کر مسجد\\nمیں جا کر بیٹھ گئے۔میں وہاں پیچھے بیٹھ کر آپ کے مونڈھے دبانے لگ گیا۔اس وقت میں نے عرض کیا کہ\\nحضور یہ آپ پر سرخی کہاں سے گرمی ہے۔حضور نے بہت بے توجہی سے فرمایا کہ آموں کا رس ہوگا اور مجھے\\nٹال دیا۔میں نے دوبارہ عرض کیا کہ حضور یہ آموں کا رس نہیں یہ تو سرخی ہے۔اس پر آپ نے سر مبارک کو\\nتھوڑی سی حرکت دے کر فرمایا ” کتھے ہے؟ یعنی کہاں ہے؟ میں نے کرتہ پر وہ نشان دکھا کر کہا کہ یہ ہے\\nاس پر حضور نے گرتے کو سامنے کی طرف کھینچ کر اور اپنے سر کو ادھر پھیر کر اس قطرہ کو دیکھا۔پھر اس کے\\nمتعلق مجھ سے کچھ نہیں فرمایا بلکہ رویت باری اور امور کشوف کے خارج میں وجود پانے کے متعلق پہلے\\nبزرگوں کے دو ایک واقعات مجھے سنائے اور فرمایا کہ خدا تعالیٰ کی ہستی وراء الوراء ہے اس کو یہ آنکھیں\\nدنیا میں نہیں دیکھ سکتیں البتہ اس کی بعض صفات جمالی یا جلالی متمثل ہو کر بزرگوں کو دکھائی دے جاتے ہیں۔شاہ عبدالقادر صاحب لکھتے ہیں کہ مجھے کئی دفعہ خدا تعالیٰ کی زیارت اپنے والد کی شکل میں ہوئی ہے نیز شاہ\\nصاحب فرماتے ہیں کہ ایک دفعہ مجھے اللہ تعالیٰ کی زیارت ہوئی اور خدا تعالیٰ نے مجھے ایک ہلدی کی گٹھی دی\\nکہ یہ میری معرفت ہے اسے سنبھال کر رکھنا جب وہ بیدار ہوئے تو ہلدی کی گٹھی ان کی مٹھی میں موجود تھی۔اور ایک بزرگ جن کا حضور نے نام نہیں بتایا تہجد کے وقت اپنے حجرہ کے اندر بیٹھے مصلی پر کچھ پڑھ رہے\\nتھے کہ انہوں نے کشف میں دیکھا کہ کوئی شخص باہر سے آیا ہے اور ان کے نیچے کا مصلی نکال کر لے گیا ہے۔جب وہ بیدار ہوئے تو دیکھا کہ فی الواقع مصلحی ان کے نیچے نہیں تھا۔جب دن نکلنے پر حجرہ سے باہر نکلے تو\\nکیا دیکھتے ہیں کہ مصلی صحن میں پڑا ہے۔یہ واقعات سنا کر حضرت صاحب نے فرمایا کہ یہ کشف کی باتیں\\nتھیں مگر خدا تعالیٰ نے ان بزرگوں کی کرامت ظاہر کرنے کیلئے خارج میں بھی ان کا وجود ظاہر کر دیا۔اب\\nہمارا قصہ سنوں۔جس وقت تم حجرہ میں ہمارے پاؤں دبا رہے تھے میں کیا دیکھتا ہوں کہ ایک نہایت وسیع اور\\nمصفی مکان ہے اس میں ایک پلنگ بچھا ہوا ہے اور اس پر ایک شخص حاکم کی صورت میں بیٹھا ہے۔میرے\\nدل میں ڈالا گیا کہ یہ احکم الحاکمین یعنی رب العالمین ہیں اور میں اپنے آپ کو ایسا سمجھتا ہوں جیسے\\nحاکم کا کوئی سر رشتہ دار ہوتا ہے۔میں نے کچھ احکام قضا و قدر کے متعلق لکھے ہیں اور ان پر دستخط کرانے کی'), Document(id='075c5279-d18a-43b5-a537-0fe7eb7ec4b9', metadata={'chunk_index': 81.0, 'page': '75', 'title': 'seerat-ul-mahdi', 'volume': 1.0}, page_content='سیرت المہدی\\n75\\nحصہ اوّل\\nغرض سے ان کے پاس لے چلا ہوں۔جب میں پاس گیا تو انہوں نے مجھے نہایت شفقت سے اپنے پاس\\nپلنگ پر بٹھا لیا۔اس وقت میری ایسی حالت ہو گئی کہ جیسے ایک بیٹا اپنے باپ سے بچھڑا ہوا سالہا سال کے\\nبعد ملتا ہے اور قد رتا اس کا دل بھر آتا ہے یا شاید فرما یا اس کو رقت آجاتی ہے اور میرے دل میں اس وقت یہ\\nبھی خیال آیا کہ احکم الحاکمین یا فرما یارب العالمین ہیں اور کس محبت اور شفقت سے انہوں نے\\nمجھے اپنے پاس بٹھا لیا ہے۔اس کے بعد میں نے وہ احکام جو لکھے تھے دستخط کرانے کی غرض سے پیش کئے۔انہوں نے قلم سرخی کی دوات میں جو پاس پڑی تھی ڈبویا اور میری طرف جھاڑ کر دستخط کر دیئے۔میاں عبداللہ\\nصاحب کہتے ہیں کہ حضرت صاحب نے قلم کے جھاڑنے اور دستخط کرنے کی حرکتوں کو خود اپنے ہاتھ کی حرکت\\nسے بنایا تھا کہ یوں کیا تھا۔پھر حضرت صاحب نے فرمایا یہ وہ سرخی ہے جو اس قلم سے نکلی ہے۔پھر فرمایا دیکھو\\nکوئی قطرہ تمہارے اوپر بھی گرا۔میں نے اپنے گرتے کو ادھر اُدھر سے دیکھ کر عرض کیا کہ حضور میرے پر تو\\nکوئی نہیں گرا۔فرمایا کہ تم اپنی ٹوپی پر دیکھو۔ان دنوں میں ململ کی سفید ٹوپی میرے سر پر ہوتی تھی میں نے وہ\\nٹوپی اتار کر دیکھی تو ایک قطرہ اس پر بھی تھا۔مجھے بہت خوشی ہوئی اور میں نے عرض کیا حضور میری ٹوپی پر بھی\\nایک قطرہ ہے۔پھر میرے دل میں یہ شوق پیدا ہوا کہ یہ گر تہ بڑا مبارک ہے اس کو تبرکاً لے لینا چاہئیے۔پہلے میں نے اس خیال سے کہ کہیں حضور جلدی انکار نہ کر دیں حضور سے مسئلہ پوچھا کہ حضور کسی بزرگ کا\\nکوئی متبرک کپڑے وغیرہ کالے کر رکھنا جائز ہے؟ فرمایا ہاں جائز ہے۔رسول اللہ ﷺ کے تبرکات صحابہ\\nنے رکھے تھے۔پھر میں نے عرض کیا کہ حضور خدا کے واسطے میرا ایک سوال ہے۔فرمایا کہو کیا ہے؟ عرض\\nکیا کہ حضور یہ گر نہ تبسر کا مجھے دے دیں۔فرمایا نہیں یہ تو ہم نہیں دیتے۔میں نے عرض کیا حضور نے ابھی تو\\nفرمایا ہے کہ رسول اللہ ﷺ کے تبرکات صحابہ نے رکھے۔اس پر فرمایا کہ یہ گر تہ میں اس واسطے نہیں دیتا کہ\\nمیرے اور تیرے مرنے کے بعد اس سے شرک پھیلے گا اس کی لوگ پوجا کریں گے۔اس کو لوگ زیارت بنالیں\\nگے۔میں نے عرض کیا کہ حضور رسول اللہ ﷺ کے تبرکات سے شرک نہ پھیلا۔فرمایا میاں عبداللہ دراصل\\nبات یہ ہے کہ رسول اللہ ﷺ کے تبرکات جن صحابہ کے پاس تھے وہ مرتے ہوئے وصیتیں کر گئے کہ ان\\nتبرکات کو ہمارے کفن کے ساتھ دفن کر دینا چنانچہ ایسا ہی کیا گیا۔جو تبرک جن صحابہ کے پاس تھا وہ ان کے')]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'**سرخ قطروں کا واقعہ (The Incident of Red Drops)**\\n\\nسرخ قطروں کا واقعہ، حضرت اقدس مسیح موعود علیہ السلام کی زندگی کا ایک نہایت اہم اور روحانی واقعہ ہے جو آپ کے کشوف اور الہامات کی صداقت اور ان کے ظاہری وجود میں ظاہر ہونے کا ایک بین ثبوت ہے۔ اس واقعہ کی تفصیل میاں عبداللہ صاحب سنوری رضی اللہ عنہ کی روایت سے سیرت المہدی میں بیان کی گئی ہے۔\\n\\n**واقعہ کی تفصیل:**\\n\\nیہ واقعہ رمضان المبارک کی ستائیسویں شب (جو شب قدر بھی ہو سکتی تھی) کو فجر کے وقت پیش آیا، جب میاں عبداللہ صاحب سنوری رضی اللہ عنہ حضرت مسیح موعود علیہ السلام کے پاؤں دبا رہے تھے۔\\n\\n1.  **سرخ قطروں کا مشاہدہ:** میاں عبداللہ صاحب نے سب سے پہلے حضرت صاحب کے پاؤں پر ٹخنے کے نیچے ایک سرخ قطرہ دیکھا جو تازہ گرے ہونے کی وجہ سے بستہ تھا۔ انہوں نے اسے انگلی سے لگا کر سونگھا لیکن اس میں کوئی خوشبو نہیں تھی۔ بعد ازاں، انہوں نے حضرت صاحب کے کرتے پر پسلیوں کے پاس ایک اور بڑا سرخ قطرہ دیکھا۔ انہیں حیرانی ہوئی کہ یہ سرخی کہاں سے آئی ہے، اور انہوں نے چھت وغیرہ میں تلاش کی لیکن کہیں کوئی خارجی ذریعہ نظر نہ آیا۔\\n\\n2.  **حضرت مسیح موعود علیہ السلام کا ابتدائی جواب:** جب میاں عبداللہ صاحب نے حضرت صاحب سے اس سرخی کے بارے میں پوچھا تو آپ نے ابتدا میں بے توجہی سے فرمایا کہ \"آموں کا رس ہوگا\" اور انہیں ٹال دیا۔ لیکن جب میاں عبداللہ صاحب نے دوبارہ عرض کیا کہ \"حضور یہ آموں کا رس نہیں یہ تو سرخی ہے،\" تو آپ نے کرتے پر نشان دیکھ کر اس قطرے کو غور سے دیکھا۔\\n\\n3.  **کشف کا انکشاف:** اس کے بعد حضرت مسیح موعود علیہ السلام نے سابقہ بزرگوں کے کشوف اور رویت باری کے متعلق واقعات سنا کر فرمایا کہ خدا تعالیٰ کی ہستی وراء الوراء ہے اور اسے دنیا میں یہ آنکھیں نہیں دیکھ سکتیں، البتہ اس کی صفات جمالی یا جلالی متمثل ہو کر بزرگوں کو دکھائی دے جاتی ہیں۔ پھر آپ نے اپنے کشف کا ذکر فرمایا:\\n    *   آپ نے دیکھا کہ ایک نہایت وسیع اور مصفی مکان ہے، جس میں ایک پلنگ پر ایک شخص حاکم کی صورت میں بیٹھا ہے (جو احکم الحاکمین یعنی رب العالمین تھے)۔\\n    *   حضرت مسیح موعود علیہ السلام اپنے آپ کو ایسا سمجھ رہے تھے جیسے حاکم کا کوئی سررشتہ دار ہوتا ہے۔\\n    *   آپ نے قضا و قدر کے متعلق کچھ احکام لکھے تھے اور ان پر دستخط کرانے کی غرض سے اللہ تعالیٰ کے پاس لے گئے۔\\n    *   اللہ تعالیٰ نے آپ کو نہایت شفقت سے اپنے پاس پلنگ پر بٹھا لیا۔ اس وقت آپ کی ایسی حالت ہو گئی جیسے ایک بیٹا اپنے باپ سے سالہا سال بعد ملتا ہے اور اس کا دل بھر آتا ہے۔\\n    *   پھر حضرت مسیح موعود علیہ السلام نے وہ احکام دستخط کرانے کے لیے پیش کیے۔ اللہ تعالیٰ نے قلم سرخی کی دوات میں ڈبویا اور آپ کی طرف جھاڑ کر دستخط کر دیے۔ حضرت مسیح موعود علیہ السلام نے خود اپنے ہاتھ کی حرکت سے قلم کے جھاڑنے اور دستخط کرنے کی کیفیت بیان فرمائی۔\\n\\n4.  **ظاہری وجود میں ظہور:** حضرت مسیح موعود علیہ السلام نے فرمایا کہ \"یہ وہ سرخی ہے جو اس قلم سے نکلی ہے۔\" پھر آپ نے میاں عبداللہ صاحب سے پوچھا کہ \"دیکھو کوئی قطرہ تمہارے اوپر بھی گرا؟\" میاں عبداللہ صاحب نے اپنے کرتے کو دیکھا تو کوئی قطرہ نہیں ملا۔ پھر حضور نے فرمایا \"تم اپنی ٹوپی پر دیکھو۔\" میاں عبداللہ صاحب نے اپنی سفید ململ کی ٹوپی اتار کر دیکھی تو اس پر بھی ایک قطرہ موجود تھا۔\\n\\n5.  **تبرک اور شرک سے بچاؤ:** میاں عبداللہ صاحب کو اس پر بہت خوشی ہوئی اور انہوں نے حضرت صاحب سے کرتے کو بطور تبرک مانگنے کا شوق پیدا ہوا۔ انہوں نے پہلے مسئلہ پوچھا کہ کیا کسی بزرگ کا متبرک کپڑا وغیرہ رکھ لینا جائز ہے؟ حضور نے فرمایا کہ ہاں جائز ہے، رسول اللہ ﷺ کے تبرکات صحابہ نے رکھے تھے۔ لیکن جب میاں عبداللہ صاحب نے کرتے کا سوال کیا تو حضرت صاحب نے فرمایا کہ \"نہیں یہ تو ہم نہیں دیتے۔\" جب میاں عبداللہ صاحب نے یاد دلایا کہ آپ نے ابھی تو فرمایا کہ رسول اللہ ﷺ کے تبرکات صحابہ نے رکھے، تو حضرت صاحب نے فرمایا کہ \"یہ کرتہ میں اس واسطے نہیں دیتا کہ میرے اور تیرے مرنے کے بعد اس سے شرک پھیلے گا اس کی لوگ پوجا کریں گے۔ اس کو لوگ زیارت بنالیں گے۔\" اور فرمایا کہ رسول اللہ ﷺ کے تبرکات جن صحابہ کے پاس تھے، وہ مرتے ہوئے وصیتیں کر گئے کہ ان تبرکات کو ہمارے کفن کے ساتھ دفن کر دینا۔\\n\\n**حاصل کلام:**\\nیہ واقعہ حضرت اقدس مسیح موعود علیہ السلام کے کشوف کی صداقت، ان کے ظاہری وجود میں ظہور، اور اللہ تعالیٰ کے ساتھ آپ کے قرب و محبت کا ایک عظیم نشان ہے۔ اس سے یہ بھی واضح ہوتا ہے کہ آپ کس قدر توحید کے علمبردار تھے اور شرک کے ادنیٰ شائبے سے بھی اپنی امت کو بچانا چاہتے تھے۔\\n\\n**حوالہ:**\\n*   سیرت المہدی جلد اول، صفحہ 73 تا 75، روایت نمبر 73.'"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_chain.invoke(\"surkh qatro ka kya waqya hai\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Gemini_LangChain_QA_Pinecone_WebLoad.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
