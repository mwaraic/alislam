{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdsMOBaBfyT0"
      },
      "source": [
        "##### Copyright 2025 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "rIIf_RgOf3sr"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TySweisNf_Am"
      },
      "source": [
        "# Gemini API: Question Answering using LangChain and Pinecone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awKO767lQIWh"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/examples/langchain/Gemini_LangChain_QA_Pinecone_WebLoad.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" height=30/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bA5Hys5PU_nt"
      },
      "source": [
        "## Overview\n",
        "\n",
        "[Gemini](https://ai.google.dev/models/gemini) is a family of generative AI models that lets developers generate content and solve problems. These models are designed and trained to handle both text and images as input.\n",
        "\n",
        "[LangChain](https://www.langchain.com/) is a data framework designed to make integration of Large Language Models (LLM) like Gemini easier for applications.\n",
        "\n",
        "[Pinecone](https://www.pinecone.io/) is a cloud-first vector database that allows users to search across billions of embeddings with ultra-low query latency.\n",
        "\n",
        "In this notebook, you'll learn how to create an application that answers questions using data from a website with the help of Gemini, LangChain, and Pinecone."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qRjVe1tZhsx"
      },
      "source": [
        "## Setup\n",
        "\n",
        "First, you must install the packages and set the necessary environment variables.\n",
        "\n",
        "### Installation\n",
        "\n",
        "Install LangChain's Python library, `langchain` and LangChain's integration package for Gemini, `langchain-google-genai`. Next, install LangChain's integration package for the new version of Pinecone, `langchain-pinecone` and the `pinecone-client`, which is Pinecone's Python SDK. Finally, install `langchain-community` to access the `WebBaseLoader` module later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olK4Ejjzuj76"
      },
      "outputs": [],
      "source": [
        "%pip install --quiet langchain-core\n",
        "%pip install --quiet langchain\n",
        "%pip install --quiet langchain-google-genai\n",
        "%pip install --quiet -U langchain-community\n",
        "%pip install --quiet pinecone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQOGMejVu-6D"
      },
      "source": [
        "## Configure your API key\n",
        "\n",
        "To run the following cell, your API key must be stored in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see [Authentication](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb) for an example.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ysayz8skEfBW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "GOOGLE_API_KEY=os.environ.get('GOOGLE_API_KEY')\n",
        "# COHERE_API_KEY=os.environ.get('COHERE_API_KEY')\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "# os.environ[\"COHERE_API_KEY\"] = COHERE_API_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPQLjFvRooqn"
      },
      "source": [
        "### Setup Pinecone\n",
        "\n",
        "To use Pinecone in your application, you must have an API key. To create an API key you have to set up a Pinecone account. Visit [Pinecone's app page](https://app.pinecone.io/), and Sign up/Log in to your account. Then navigate to the \"API Keys\" section and copy your API key.\n",
        "\n",
        "For more detailed instructions on getting the API key, you can read Pinecone's [Quickstart documentation](https://docs.pinecone.io/docs/quickstart#2-get-your-api-key).\n",
        "\n",
        "Set the environment variable `PINECONE_API_KEY` to configure Pinecone to use your API key.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "A7jTZLEApgtm"
      },
      "outputs": [],
      "source": [
        "PINECONE_API_KEY=os.environ.get('PINECONE_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGOKV3XflBCe"
      },
      "source": [
        "## Basic steps\n",
        "LLMs are trained offline on a large corpus of public data. Hence they cannot answer questions based on custom or private data accurately without additional context.\n",
        "\n",
        "If you want to make use of LLMs to answer questions based on private data, you have to provide the relevant documents as context alongside your prompt. This approach is called Retrieval Augmented Generation (RAG).\n",
        "\n",
        "You will use this approach to create a question-answering assistant using the Gemini text model integrated through LangChain. The assistant is expected to answer questions about Gemini model. To make this possible you will add more context to the assistant using data from a website.\n",
        "\n",
        "In this tutorial, you'll implement the two main components in an RAG-based architecture:\n",
        "\n",
        "1. Retriever\n",
        "\n",
        "    Based on the user's query, the retriever retrieves relevant snippets that add context from the document. In this tutorial, the document is the website data.\n",
        "    The relevant snippets are passed as context to the next stage - \"Generator\".\n",
        "\n",
        "2. Generator\n",
        "\n",
        "    The relevant snippets from the website data are passed to the LLM along with the user's query to generate accurate answers.\n",
        "\n",
        "You'll learn more about these stages in the upcoming sections while implementing the application."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPhs4mDkjdgY"
      },
      "source": [
        "## Import the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TcvGPVdXu05F"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
            "/Users/mwaraich/alislam/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from langchain import hub\n",
        "from langchain import PromptTemplate\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.schema import StrOutputParser\n",
        "from langchain.schema.prompt_template import format_document\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "from pinecone import PodSpec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZ3tM0T2lbVm"
      },
      "source": [
        "## Retriever\n",
        "\n",
        "In this stage, you will perform the following steps:\n",
        "\n",
        "1. Read and parse the website data using LangChain.\n",
        "\n",
        "2. Create embeddings of the website data.\n",
        "\n",
        "    Embeddings are numerical representations (vectors) of text. Hence, text with similar meaning will have similar embedding vectors. You'll make use of Gemini's embedding model to create the embedding vectors of the website data.\n",
        "\n",
        "3. Store the embeddings in Pinecone's vector store.\n",
        "    \n",
        "    Pinecone is a vector database. The Pinecone vector store helps in the efficient retrieval of similar vectors. Thus, for adding context to the prompt for the LLM, relevant embeddings of the text matching the user's question can be retrieved easily using Pinecone.\n",
        "\n",
        "4. Create a Retriever from the Pinecone vector store.\n",
        "\n",
        "    The retriever will be used to pass relevant website embeddings to the LLM along with user queries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2N-NCPElqN3"
      },
      "source": [
        "### Read and parse the website data\n",
        "\n",
        "LangChain provides a wide variety of document loaders. To read the website data as a document, you will use the `WebBaseLoader` from LangChain.\n",
        "\n",
        "To know more about how to read and parse input data from different sources using the document loaders of LangChain, read LangChain's [document loaders guide](https://python.langchain.com/docs/integrations/document_loaders)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8NXNTrjp0jdh"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "gemini_embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-exp-03-07\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr5xeWUXmnUe"
      },
      "source": [
        "### Store the data using Pinecone\n",
        "\n",
        "\n",
        "To create a Pinecone vector database, first, you have to initialize your Pinecone client connection using the API key you set previously.\n",
        "\n",
        "In Pinecone, vector embeddings have to be stored in indexes. An index represents the vector data's top-level organizational unit. The vectors in any index must have the same dimensionality and distance metric for calculating similarity. You can read more about indexes in [Pinecone's Indexes documentation](https://docs.pinecone.io/docs/indexes).\n",
        "\n",
        "First, you'll create an index using Pinecone's `create_index` function. Pinecone allows you to create two types of indexes, Serverless indexes and Pod-based indexes. Pinecone's free starter plan lets you create only one project and one pod-based starter index with sufficient resources to support 100,000 vectors. For this tutorial, you have to create a pod-based starter index. To know more about different indexes and how they can be created, read Pinecone's [create indexes guide](https://docs.pinecone.io/docs/new-api#creating-indexes).\n",
        "\n",
        "\n",
        "Next, you'll insert the documents you extracted earlier from the website data into the newly created index using LangChain's `Pinecone.from_documents`. Under the hood, this function creates embeddings from the documents created by the document loader of LangChain using any specified embedding model and inserts them into the specified index in a Pinecone vector database.  \n",
        "\n",
        "You have to specify the `docs` you created from the website data using LangChain's `WebBasedLoader` and the `gemini_embeddings` as the embedding model when invoking the `from_documents` function to create the vector database from the website data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "n1VwhUQMvpcN"
      },
      "outputs": [],
      "source": [
        "from pinecone import Pinecone as pc\n",
        "\n",
        "# Initialize Pinecone client\n",
        "pine_client = pc(api_key=\"pcsk_3NGhRC_2Eg2DzYQKdYXBv1ReHB6EYoBjsKCoCzm5BJe1HeKH8LRbm3CdL6h6bmasJna9vo\")\n",
        "index_name = \"fiqh\"\n",
        "index = pine_client.Index(index_name, \"https://fiqh-vm3wi2f.svc.aped-4627-b74a.pinecone.io\")\n",
        "vectorstore = PineconeVectorStore(\n",
        "    index=index,\n",
        "    embedding=gemini_embeddings\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Seerat-ul-Mahdi\n",
        "https://new.alislam.org/library/books/seerat-ul-mahdi-vol-1?option=options&page=9\n",
        "\n",
        "https://new.alislam.org/library/books/seerat-ul-mahdi-vol-2?option=options&page=8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [],
      "source": [
        "def update_seerat_entry(entry, jild_number):\n",
        "    \"\"\"\n",
        "    Updates the 'content' of a single entry to include:\n",
        "    سیرت المہدی، جلد {جلد نمبر}، صفحہ {صفحہ نمبر}\n",
        "    \n",
        "    Parameters:\n",
        "    - entry: dict with 'content' and 'pageNum'\n",
        "    - jild_number: int, the جلد (volume) number to insert\n",
        "    \n",
        "    Returns:\n",
        "    - Updated entry (dict) with modified 'content'\n",
        "    \"\"\"\n",
        "    page_number = entry.get('printPageNum', '')\n",
        "    content = entry.get('content', '')\n",
        "\n",
        "    # Split the content at the first two newlines\n",
        "    split_content = content.split('\\n', 2)\n",
        "\n",
        "    if len(split_content) >= 3:\n",
        "        # Replace the first two lines with formatted title\n",
        "        new_header = f'سیرت المہدی، جلد {jild_number}، صفحہ {page_number}'\n",
        "        entry['content'] = f'{new_header}\\n{split_content[2]}'\n",
        "\n",
        "    return entry\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from time import sleep\n",
        "import requests\n",
        "\n",
        "books = {\n",
        "    \"1342-12460\": {\n",
        "        \"jild_number\": 1,\n",
        "        \"start_page\": 9,\n",
        "        \"end_page\": 834\n",
        "    },\n",
        "    \"1342-12463\": {\n",
        "        \"jild_number\": 2,\n",
        "        \"start_page\": 8,\n",
        "        \"end_page\": 439\n",
        "    }\n",
        "}\n",
        "for book_id, book_data in books.items():\n",
        "    jild_number = book_data[\"jild_number\"]\n",
        "    for i in range(book_data[\"start_page\"], book_data[\"end_page\"]):\n",
        "        url = f\"https://new.alislam.org/api/books/text?id={book_id}&pages={i}\"\n",
        "        response = requests.get(url)\n",
        "        entry =update_seerat_entry(response.json()[0], jild_number)\n",
        "        text = entry['content']\n",
        "        page_number = entry.get('printPageNum', '')\n",
        "        sleep(1)\n",
        "        vectorstore.add_documents([Document(page_content=text, metadata={\"chunk_index\": i, \"volume\": jild_number, \"title\": \"seerat-ul-mahdi\", \"page\": page_number})])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fiqh ul Masih\n",
        "\n",
        "https://new.alislam.org/api/books/text?id=ur-1197&pages=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [],
      "source": [
        "def update_fiqh_ul_masih_entry(entry):\n",
        "    \"\"\"\n",
        "    Updates the 'content' of a single entry to include:\n",
        "    فقه المسيح، صفحہ {صفحہ نمبر}\n",
        "    \n",
        "    Parameters:\n",
        "    - entry: dict with 'content' and 'pageNum'\n",
        "    \n",
        "    Returns:\n",
        "    - Updated entry (dict) with modified 'content'\n",
        "    \"\"\"\n",
        "    page_number = entry.get('printPageNum', '')\n",
        "    content = entry.get('content', '')\n",
        "\n",
        "    # Split the content at the first two newlines to grab the title and narration number\n",
        "    split_content = content.split('\\n', 2)\n",
        "\n",
        "    if len(split_content) >= 3:\n",
        "        # Extract title (first line)\n",
        "        title = split_content[0]\n",
        "        \n",
        "        # Create the new header with page number\n",
        "        new_header = f'{title}، صفحہ {page_number}'\n",
        "        \n",
        "        # Update the content with the new header and the rest of the text\n",
        "        entry['content'] = f'{new_header}\\n{split_content[2]}'\n",
        "\n",
        "    return entry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [],
      "source": [
        "from time import sleep\n",
        "import requests\n",
        "\n",
        "books = {\n",
        "    \"ur-1197\": {\n",
        "        \"start_page\": 58,\n",
        "        \"end_page\": 612\n",
        "    }\n",
        "}\n",
        "for book_id, book_data in books.items():\n",
        "    for i in range(book_data[\"start_page\"], book_data[\"end_page\"]):\n",
        "        url = f\"https://new.alislam.org/api/books/text?id={book_id}&pages={i}\"\n",
        "        response = requests.get(url)\n",
        "        entry =update_fiqh_ul_masih_entry(response.json()[0])\n",
        "        text = entry['content']\n",
        "        page_number = entry.get('printPageNum', '')\n",
        "        sleep(1)\n",
        "        vectorstore.add_documents([Document(page_content=text, metadata={\"chunk_index\": i, \"title\": \"fiqh-ul-masih\", \"page\": page_number})])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuSjapvHnc6T"
      },
      "source": [
        "### Create a retriever using Pinecone\n",
        "\n",
        "You'll now create a retriever that can retrieve website data embeddings from the newly created Pinecone vector store. This retriever can be later used to pass embeddings that provide more context to the LLM for answering user's queries.\n",
        "\n",
        "Invoke the `as_retriever` function of the vector store you initialized in the last step, to create a retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n"
          ]
        }
      ],
      "source": [
        "\n",
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
        "# Check if the retriever is working by trying to fetch the relevant docs related\n",
        "# to the word 'MMLU'(Massive Multitask Language Understanding). If the length is\n",
        "# greater than zero, it means that the retriever is functioning well.\n",
        "print(len(retriever.invoke(\"mufti muhammad sadiq\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Qw00lvPnjfR"
      },
      "source": [
        "## Generator\n",
        "\n",
        "The Generator prompts the LLM for an answer when the user asks a question. The retriever you created in the previous stage from the Pinecone vector store will be used to pass relevant embeddings from the website data to the LLM to provide more context to the user's query.\n",
        "\n",
        "You'll perform the following steps in this stage:\n",
        "\n",
        "1. Chain together the following:\n",
        "    * A prompt for extracting the relevant embeddings using the retriever.\n",
        "    * A prompt for answering any question using LangChain.\n",
        "    * An LLM model from Gemini for prompting.\n",
        "    \n",
        "2. Run the created chain with a question as input to prompt the model for an answer.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2MK2wLwnkLg"
      },
      "source": [
        "### Initialize Gemini\n",
        "\n",
        "You must import `ChatGoogleGenerativeAI` from LangChain to initialize your model.\n",
        " In this example, you will use **gemini-2.0-flash**, as it supports text summarization. To know more about the text model, read Google AI's [language documentation](https://ai.google.dev/models/gemini).\n",
        "\n",
        "You can configure the model parameters such as ***temperature*** or ***top_p***,  by passing the appropriate values when initializing the `ChatGoogleGenerativeAI` LLM.  To learn more about the parameters and their uses, read Google AI's [concepts guide](https://ai.google.dev/docs/concepts#model_parameters)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "CaA1vRCh7s36"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# To configure model parameters use the `generation_config` parameter.\n",
        "# eg. generation_config = {\"temperature\": 0.7, \"topP\": 0.8, \"topK\": 40}\n",
        "# If you only want to set a custom temperature for the model use the\n",
        "# \"temperature\" parameter directly.\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-preview-05-20\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BeLN6RXnuS2"
      },
      "source": [
        "### Create prompt templates\n",
        "\n",
        "You'll use LangChain's [PromptTemplate](https://python.langchain.com/docs/how_to/#prompt-templates) to generate prompts to the LLM for answering questions.\n",
        "\n",
        "In the `llm_prompt`, the variable `question` will be replaced later by the input question, and the variable `context` will be replaced by the relevant text from the website retrieved from the Pinecone vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "90Czqh074dEC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_variables=['book', 'question'] input_types={} partial_variables={} template='You are an Ahmadi scholar who writes counter arguments against Non-Ahmadi scholars.\\nUse the following books to write arguments.\\nAdd reference to the sources of the argument.\\n\\nQuestion: {question}\\nBooks: {book}\\nAnswer:'\n"
          ]
        }
      ],
      "source": [
        "# Prompt template to query Gemini\n",
        "llm_prompt_template = \"\"\"You are an Ahmadi scholar who writes counter arguments against Non-Ahmadi scholars.\n",
        "Use the following books of the Promised Messiah A.S to write counter arguments.\n",
        "Add references to the sources of the argument for example: Ruhani Khazain Vol. X Pg. X\n",
        "\n",
        "Question: {question}\n",
        "Books: {book}\n",
        "Answer:\"\"\"\n",
        "\n",
        "llm_prompt = PromptTemplate.from_template(llm_prompt_template)\n",
        "\n",
        "print(llm_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_variables=['book', 'question'] input_types={} partial_variables={} template='You are an Ahmadi scholar who answer general questions.\\nUse the following books of to answer questions.\\nAdd references to the sources of the answer for example: Ruhani Khazain Vol. X Pg. X, Seerat ul Mahdi Vol. X Part X. Pg. X\\n\\nQuestion: {question}\\nBooks: {book}\\nAnswer:'\n"
          ]
        }
      ],
      "source": [
        "# Prompt template to query Gemini\n",
        "llm_prompt_template = \"\"\"You are an Ahmadi scholar who answer general questions.\n",
        "Use the following books of to answer questions.\n",
        "Add references to the sources of the answer for example: Ruhani Khazain Vol. X Pg. X, Seerat ul Mahdi Vol. X Part X. Pg. X\n",
        "\n",
        "Question: {question}\n",
        "Books: {book}\n",
        "Answer:\"\"\"\n",
        "\n",
        "llm_prompt = PromptTemplate.from_template(llm_prompt_template)\n",
        "\n",
        "print(llm_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkWpzMmpnx7b"
      },
      "source": [
        "### Create a stuff documents chain\n",
        "\n",
        "LangChain provides [Chains](https://python.langchain.com/docs/modules/chains/) for chaining together LLMs with each other or other components for complex applications. You will create a **stuff documents chain** for this application. A stuff documents chain lets you combine all the relevant documents, insert them into the prompt, and pass that prompt to the LLM.\n",
        "\n",
        "You can create a stuff documents chain using the [LangChain Expression Language (LCEL)](https://python.langchain.com/docs/expression_language).\n",
        "\n",
        "To learn more about different types of document chains, read LangChain's [chains guide](https://python.langchain.com/docs/modules/chains/document/).\n",
        "\n",
        "The stuff documents chain for this application retrieves the relevant website data and passes it as the context to an LLM prompt along with the input question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "gj5sWzpwp7vc"
      },
      "outputs": [],
      "source": [
        "# Combine data from documents to readable string format.\n",
        "def format_docs(docs):\n",
        "    print(docs)\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "# Create stuff documents chain using LCEL.\n",
        "# This is called a chain because you are chaining\n",
        "# together different elements with the LLM.\n",
        "# In the following example, to create a stuff chain,\n",
        "# you will combine content, prompt, LLM model, and\n",
        "# output parser together like a chain using LCEL.\n",
        "#\n",
        "# The chain implements the following pipeline:\n",
        "# 1. Extract data from documents and save to the variable `context`.\n",
        "# 2. Use the `RunnablePassthrough` option to provide question during invoke.\n",
        "# 3. The `context` and `question` are then passed to the prompt and\n",
        "#    input variables in the prompt are populated.\n",
        "# 4. The prompt is then passed to the LLM (`gemini-2.0-flash`).\n",
        "# 5. Output from the LLM is passed through an output parser\n",
        "#    to structure the model response.\n",
        "rag_chain = (\n",
        "    {\"book\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | llm_prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmHx_F7DoMgM"
      },
      "source": [
        "### Prompt the model\n",
        "\n",
        "You can now query the LLM by passing any question to the `invoke()` function of the stuff documents chain you created previously."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "95W-sbTjoGGj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Document(id='3ea5823b-757e-4b00-91eb-98ed6a319ecd', metadata={'chunk_index': 9.0, 'page': 110.0, 'title': 'اِزالہ اوھام', 'volume': '۳'}, page_content='روحانی خزائن ۔ کمپیوٹرائزڈوہ الفاظ بیان نہیں فرمائے جو اس عاجز نے بزعم ان کے اپنی تالیفات میں استعمال کئے ہیں اور درحقیقت سب و شتم میں داخل ہیں۔میں سچ سچ کہتا ہوں کہ جہاں تک مجھے معلوم ہے میں نے ایک لفظ بھی ایسا استعمال نہیں کیا جس کو دشنام دہی کہا جائے بڑے دھوکہ کی با ت یہ ہے کہ اکثر لوگ دشنام دہی اور بیان واقعہ کو ایک ہی صورت میں سمجھ لیتے ہیں اور ان دونوں مختلف مفہوموں میں فرق کرنا نہیں جانتے بلکہ ایسی ہریک بات کو جو دراصل ایک واقعی امر کا اظہار ہو اور اپنے محل پر چسپاں ہو محض اس کی کسی قدر مرارت کی وجہ سے جو حق گوئی کے لازم حال ہوا کرتی ہے دشنام ہی تصور کر لیتے ہیں حالانکہ دشنام اور سب اور شتم فقط اس مفہوم کا نام ہے جو خلاف واقعہ اور دروغ کے طور پر محض آزار رسانی کی غرض سے استعمال کیا جائے اور اگر ہریک سخت اور آزار دہ تقریر کو محض بوجہ اس کے مرارت اور تلخی اور ایذارسانی کے دشنام کے مفہوم میں داخل کر سکتے ہیں تو پھر اقرار کرنا پڑے گا کہ سارا قرآن ؔ شریف گالیوں سے پُر ہے کیونکہ جو کچھ بتوں کی ذلت اور ُ بت پرستوں کی حقارت اور ان کے بارہ میں *** ملامت کے سخت الفاظ قرآن شریف میں استعمال کئے گئے ہیں یہ ہرگز ایسے نہیں ہیں جن کے سننے سے بت پرستوں کے دل خوش ہوئے ہوں بلکہ بلاشبہ ان الفاظ نے ان کے غصہ کی حالت کی بہت تحریک کی ہو گی۔کیا خدائے تعالیٰ کا کفار مکہ کو مخاطب کرکے یہ فرمانا کہاِنَّكُمْ وَمَا تَعْبُدُوْنَ مِنْ دُوْنِ اللّٰهِ حَصَبُ جَهَـنَّمَ  ۱\\u0602   معترض کے من گھڑت قاعدہ کے موافق گالی میں داخل نہیں ہے کیا خدائے تعالیٰ کا قرآن شریف میں کفار کو شَرُّالْبَرِیَّۃ قرار دینا اور تمام رذیل اور پلید مخلوقات سے انہیں بد تر ظاہر کرنا یہ معترض کے خیال کے روسے دشنام دہی میں داخل نہیں ہوگا؟کیاخدائے تعالیٰ نے قرآن شریف میں وَاغْلُظْ عَلَيْهِمْ\\tْ ۲\\u0602 نہیں فرمایا کیا مومنوں کی علامات میںاَشِدَّآءُ عَلَى الْكُفَّارِ ۳\\u0602 نہیں رکھا گیا کیا حضرت مسیح کا یہودیوں کے معزز فقیہوں اور فریسیوں کو سؤر اور کتے کے نام سے پکارنا اور گلیل کے عالی مرتبہ فرمانروا ہیرودیس کا لونبڑی نام ؔ رکھنا اور معزز سردار کاہنوں اور فقیہوں کو۱\\u0602 الانبیاء: ۹۹  ۲\\u0602 التوبۃ:۷۳\\t    ۳\\u0602 الفتح:۳۰Ruhani Khazain Volume 3. Page: 110'), Document(id='7227b892-b9c6-468f-b1f1-809d7f1a0a76', metadata={'chunk_index': 15.0, 'page': 116.0, 'title': 'اِزالہ اوھام', 'volume': '۳'}, page_content='http://www.alislam.org/library/brow...in_Computerised/?l=Urdu&p=3#page/115/mode/1upجس قدر مشرکین کا کینہ ترقی کر گیاتھا اس کا اصل باعث وہ سخت الفاظ ہی تھے جو اُن نادانوں نے دشنام دہی کی صورت پرسمجھ لئے تھے جن کی وجہ سے آخر لسان سے سنان تک نوبت پہنچی ورنہ اول حال تو وہ لوگ ایسے نہیں تھے بلکہ کمال اعتقاؔ د سے آنحضرت صلی اللہ علیہ وسلم کی نسبت کہا کرتے تھے کہ عَشِقَ مُحَمَّدٌ عَلیٰ رَبِّہٖ ۔ یعنی محمد صلی اللہ علیہ وسلم اپنے رب پر عاشق ہو گئے ہیں جیسے آج کل کے ہندو لوگ بھی کسی گوشہ نشین فقیر کو ہرگز بُرا نہیں کہتے بلکہ نذریں نیازیں دیتے ہیں۔اس جگہ مجھے نہایت افسوس اور غمگین دل کے ساتھ اس بات کے ظاہر کرنے کی بھی حاجت پڑی ہے کہ یہ اعتراض جو مجھ پر گیا ہے یہ صرف عوام الناس کی طرف سے ہی نہیں بلکہ میں نے سنا ہے کہ بانی مبانی اس اعتراض کے بعض علماء بھی ہیں۔سو میں ان کی شان میں یہ تو ظن نہیں کر سکتاکہ وہ قرآن شریف اور کتب سابقہ سے بے خبر ہیں اور نہ کسی طور سے جائے ظن ہے * لیکن ؔ میں جانتاہوں کہ آج کل کی یورپ کی جھوٹی تہذیب نےقرآؔ ن شریف جس آوازبلند سے سخت زبانی کے طریق کواستعمال کر رہا ہے ایک غایت درجہ کا غبی اور سخت درجہ کا نادان بھی اُس سے بے خبر نہیں رہ سکتا۔ مثلًا زمانہ حال کے مہذبین کے نزدیک کسی پر *** بھیجنا ایک سخت گالی ہے۔ لیکن قرآن شریف کفارؔ کو سُنا سُنا کر ان پر *** بھیجتا ہے جیسا کہ فرماتا ہےاُولٰٓٮِٕكَ عَلَيْهِمْ لَعْنَةُ اللّٰهِ وَالْمَلٰٓٮِٕكَةِ وَالنَّاسِ اَجْمَعِيْنَۙ۱\\u0602 الجزو ۲ سورۃ بقرہ۔\\t خٰلِدِيْنَ فِيْهَاۚاُولٰٓٮِٕكَ يَلْعَنُهُمُ اللّٰهُ وَ يَلْعَنُهُمُ اللّٰعِنُوْنَۙ\\u200f   ۲\\u0602۔\\tالجزو نمبر ۲ایسا ہی ظاہر ہے کہ کسی انسان کو حیوان کہنا بھی ایک قسم کی گالی ہے۔ لیکن قرآن شریف نہ صرف حیوان بلکہ کفار اور منکرین کو دنیا کے تمام حیوانات سے بد تر قرار دیتا ہے جیسا کہ فرماتا ہےاِنَّ شَرَّ الدَّوَآبِّ عِنْدَ اللّٰهِ الَّذِيْنَ كَفَرُوْ\\t\\t   ۳\\u0602۔ ایسا ہی ظاہرہے کہ کسی خاص آدمی کانام لے کر یا اؔ شارہ کے طورپر اس کو نشانہ بنا کر گالی دینا زمانہ حال کیRuhani Khazain Volume 3. Page: 116'), Document(id='9cb3d96b-5a2c-474c-8bc6-ad80d1c20b1d', metadata={'chunk_index': 16.0, 'page': 117.0, 'title': 'اِزالہ اوھام', 'volume': '۳'}, page_content='http://www.alislam.org/library/brow...in_Computerised/?l=Urdu&p=3#page/116/mode/1upجو ایمانی غیّوری سے بہت دُور پڑی ہوئی ہے ہمارے علماء کے دلوں کو بھی کسی قدر دبا لیا ہے۔اس سخت آندھی کے چلنے کی وجہ سے ان کی آنکھوں میں بھی کچھ غبارساپڑگیاہے اور ان کی فطرتی کمزوری اس نزلہ کو قبول کر گئی ہے۔اسی وجہ سے وہ ایسے خیالات پر زور دیتے ہیں جن کا کوئی اصل صحیح حدیث و قرآن میں نہیں پایا جاتا ہاں یورپ کی اخلاقی کتابوں میں تو ضرور پایا جاتا ہے اور اؔ ن اخلاق میں یورپ نے یہاں تک ترقی کی ہے کہ ایک جوان عورت سے ایک نامحرم طالب کی بکلّی دل شکنی مناسب نہیں سمجھی گئی۔مگر کیا قرآن شریف یورپ کے ان اخلاق سے اتفاق رائے کرتا ہے؟ کیا وہ ایسے لوگوں کا نام دیّوث نہیں رکھتا؟ میں ایسے علماء کو محض للہ متنبہ کرتا ہوں کہ وہ ایسی نکتہ چینیاں کرنے اور ایسے خیالات کو دل میں جگہ دینے سے حق اور حق بینی سے بہت دور جاپڑے ہیں اگر وہ مجھ سے لڑنے کو تیار ہوں تو اپنی خشکؔ منطق سے جو چاہیں کہیں لیکن اگر وہ خدائے تعالیٰ سے خوف کر کے کسی قدرسوچیں تو یہ ایسی بات نہیں ہے جو ان کی نظر سے پوشیدہ رہ سکے نیک بختتہذیب کے برخلاف ہے لیکن خدائے تعالیٰ نے قرآن شریف میں بعض کا نام ابو لہب اوربعض کانام کلب اور خنزیر کہا اور ابو جہل تو خود مشہور ہے ایسا ہی ولید (بن) مغیرہ کی نسبت نہایت درجہ کے سخت الفاظ جو بصورت ظاہر گندی گالیاں معلوم ہوتی ہیں استعمال کئے ہیں جیساکہ فرماتا ہےفَلَا تُطِعِ الْمُكَذِّبِيْنَ\\t وَدُّوْا لَوْ تُدْهِنُ فَيُدْهِنُوْنَ   وَلَا تُطِعْ كُلَّ حَلَّافٍ مَّهِيْنٍۙ\\u200fهَمَّازٍ مَّشَّآءٍۢ بِنَمِيْمٍۙ   مَّنَّاعٍ لِّلْخَيْرِ مُعْتَدٍ اَثِيْمٍۙ عُتُلٍّ ۢ بَعْدَ ذٰلِكَ زَنِيْمٍۙ\\u200fسَنَسِمُهٗ عَلَى الْخُـرْطُوْمِ۔۱\\u0602 دیکھوؔ سورہ القلم الجزو نمبر ۲۹۔ یعنی تُو ان مکذّبوں کے کہنے پر مت چل جو بدل اس بات کے آرزو مند ہیں کہ ہمارے معبودوں کو بُرامت کہو اور ہمارے مذہب کی ہجو مت کرو تو پھر ہم بھی تمہارے مذہب کی نسبت ہاں میں ہاں ملاتے رہیں گے اور ان کی چرب زبانی کا خیال مت کر ویہ شخص جو مداہنہ کا خواستگار ہے جھوٹی قسمیں کھانے والااورضعیف الرائے اور ذلیل آدمی ہے دوسروں کے عیب ڈھونڈنے والا اورسخن چینی سے لوگوں میں تفرقہ ڈالنے والاؔ اورنیکی کی\\t\\t    ۱\\u0602 القلم: ۹ تا ۱۷Ruhani Khazain Volume 3. Page: 117')]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'The allegation made by Muhammad Imtiaz against the Promised Messiah, Hazrat Mirza Ghulam Ahmad (peace be upon him), regarding the use of \"bad language\" and the claim that he stated \"all the Quran is full of swears,\" is a grave misrepresentation and a distortion of his words.\\n\\nThe Promised Messiah (peace be upon him) categorically denied using any language that could be termed as \\'abusive\\' or \\'swearing\\' (dushnam-dehi). He clarified that there is a fundamental difference between true abuse and a statement of fact, which many people mistakenly conflate.\\n\\nHe states:\\n\"I truly say that as far as I know, I have not used a single word that can be called abusive. It is a great deception that most people consider abusive language and a statement of fact to be the same, and they do not know how to differentiate between these two distinct concepts. Rather, they consider every such statement, which is actually an expression of a factual matter and relevant to its context, as abuse merely due to some bitterness which is inherent in speaking the truth. Whereas, abuse, vilification, and swearing is only the name for that meaning which is used contrary to facts and falsely, merely for the purpose of causing harm.\"\\n(Ruhani Khazain, Vol. 3, Izala Auham, p. 110)\\n\\nRegarding the specific statement that \"all the Quran is full of swears,\" the Promised Messiah (peace be upon him) did *not* say this as an accusation against the Holy Quran. Rather, he used a rhetorical argument (a *reductio ad absurdum*) to expose the flawed and superficial understanding of \"abuse\" held by his critics. He argued that *if* every harsh or painful statement were to be considered \\'abuse\\' merely due to its bitterness, harshness, or hurtful nature, then one would logically have to concede that the entire Holy Quran would also fall under such a definition, which is an absurd conclusion, thus proving the critics\\' definition of \\'abuse\\' to be incorrect.\\n\\nHe elaborates on this point by providing numerous examples from the Holy Quran and the practice of earlier Prophets:\\n\\n1.  **Quranic Statements about Idolaters and Idols:**\\n    The Promised Messiah (peace be upon him) asks if the Quranic statements regarding the degradation of idols and the contempt for idolaters, and the severe words of admonition used against them, would not be considered \"abuse\" by the critics\\' standard. He questions:\\n    \"Does not Allah Almighty\\'s addressing the disbelievers of Mecca and saying, \\'Are you and what you worship besides Allah, fuel for Hell?\\' (Holy Quran, 21:99) fall under abuse according to the fabricated rule of the objector? Does not Allah Almighty\\'s declaring the disbelievers in the Holy Quran as \\'the worst of creatures\\' (sharru al-bariyyah) and showing them to be worse than all vile and impure creations, fall under abuse according to the objector\\'s view?\"\\n    (Ruhani Khazain, Vol. 3, Izala Auham, p. 110)\\n\\n2.  **Divine Commands for Severity:**\\n    He further points out:\\n    \"Has not Allah Almighty commanded in the Holy Quran, \\'And be harsh with them\\' (waghlaẓ \\'alayhim) (Holy Quran, 9:73)? Has it not been included in the signs of believers that they are \\'severe against the disbelievers\\' (ashiddaa\\'u \\'alal kuffar) (Holy Quran, 48:30)?\"\\n    (Ruhani Khazain, Vol. 3, Izala Auham, p. 110)\\n\\n3.  **Quranic Curses:**\\n    The Promised Messiah (peace be upon him) also highlights that while contemporary civilized people consider cursing a severe form of abuse, the Holy Quran openly curses disbelievers:\\n    \"For example, according to the civilized people of the present age, to curse someone is a severe abuse. But the Holy Quran curses the disbelievers openly, as it says: \\'Upon them is the curse of Allah and of the angels and of all mankind\\' (Holy Quran, 2:162); \\'Allah curses them and those who curse also curse them\\' (Holy Quran, 2:160).\"\\n    (Ruhani Khazain, Vol. 3, Izala Auham, p. 115)\\n\\n4.  **Calling People Animals:**\\n    He continues:\\n    \"Similarly, it is clear that calling a human being an animal is also a type of abuse. But the Holy Quran not only calls disbelievers and deniers animals, but declares them worse than all animals of the world, as it says: \\'Verily, the worst of beasts in the sight of Allah are those who disbelieve\\' (Holy Quran, 8:56).\"\\n    (Ruhani Khazain, Vol. 3, Izala Auham, p. 115)\\n\\n5.  **Naming and Specific Descriptions of Opponents:**\\n    The Promised Messiah (peace be upon him) points out that the Holy Quran even named specific individuals and used very harsh descriptions for them:\\n    \"Similarly, it is clear that to abuse a specific person by name or by indication is against the present age\\'s civilization. But Allah Almighty in the Holy Quran called some by the name of Abu Lahab and some by the name of dog (Kalab) and pig (Khanzeer), and Abu Jahl is himself famous. Similarly, regarding Walid bin Mughira, extremely harsh words have been used which outwardly appear to be filthy abuses, as it says: \\'So yield not to the disbelievers, who wish that thou shouldst compromise, so that they too might compromise. And yield not to every contemptible swearer of oaths, a slanderer, going about with calumnies, a hinderer of good, a transgressor, a sinner, cruel, besides all that, of doubtful birth. We shall brand him on the snout.\\' (Holy Quran, 68:9-17).\"\\n    (Ruhani Khazain, Vol. 3, Izala Auham, p. 116-117)\\n\\n6.  **Example of Prophet Jesus (peace be upon him):**\\n    He also cites the example of Prophet Jesus (peace be upon him) who used strong language against his opponents:\\n    \"Did not حضرت مسیح (peace be upon him) call the respected Jewish scribes and Pharisees \\'swine\\' and \\'dogs,\\' and name the high-ranking ruler of Galilee, Herod, a \\'fox\\'?\"\\n    (Ruhani Khazain, Vol. 3, Izala Auham, p. 110)\\n\\nThe Promised Messiah (peace be upon him) attributed this faulty understanding of \"abuse\" among some \\'ulama\\' to the influence of \"Europe\\'s false civilization\" (یورپ کی جھوٹی تہذیب) and its \"dry logic\" (خشک منطق), which he believed had somewhat suppressed their natural Islamic zeal and understanding of the Quran and Hadith. He admonished them to fear God and reflect on these matters rather than succumbing to external, un-Islamic ethical standards.\\n\\nIn conclusion, the Promised Messiah (peace be upon him) did not claim that the Holy Quran is \"full of swears\" in a literal or derogatory sense. Instead, he used this strong rhetorical device to demonstrate that if his critics\\' definition of \"abuse\" were consistently applied, it would lead to the absurd conclusion that even the Holy Quran, which uses strong language against falsehood and evil, would be deemed \"abusive.\" His aim was to defend the truth and the necessary forthrightness in condemning falsehood, just as the Holy Quran and previous Prophets did. His language, therefore, was a statement of fact and a defense of divine truth, not an act of baseless abuse.'"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_chain.invoke(\"\"\"*Argument (Made by Muhammad Imtiaz against MGA): QURAAN IS FULL OF SWEARS\n",
        "Replying to the allegations of using bad language against hindu, christians and muslim opponents, Mirza Ghulam Qadiani says if his language is considered as the abusive language then all the Quraan is full of swears. (NAUZUBILLAH Min Zalik.)\n",
        "Give a response.\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Document(id='b3291a68-e2af-4f87-a19c-ebaa9db5bb32', metadata={'chunk_index': 257.0, 'page': '200', 'title': 'fiqh-ul-masih'}, page_content='فقه المسيح، صفحہ 200\\nروزہ اور رمضان\\nحکیم محمد حسین :۔بہت اچھا حضور۔انشاء اللہ کوئی تکلیف نہیں ہوگی۔حضرت اقدس: (بابا چٹو کو خطاب کر کے ) آپ تو مسافر ہیں۔روزہ تو نہیں رکھا ہوگا ؟\\nبابا چٹو۔نہیں مجھے تو روزہ ہے میں نے رکھ لیا ہے۔حضرت اقدس: اصل بات یہ ہے کہ قرآن شریف کی رخصتوں پر عمل کرنا بھی تقویٰ ہے۔خدا تعالیٰ نے مسافر اور بیمار کو دوسرے وقت رکھنے کی اجازت اور رخصت دی ہے اس لئے اس\\nحکم پر بھی تو عمل رکھنا چاہیے۔میں نے پڑھا ہے کہ اکثر اکابر اس طرف گئے ہیں کہ اگر کوئی\\nحالت سفر یا بیماری میں روزہ رکھتا ہے تو یہ معصیت ہے۔کیوں کہ غرض تو اللہ تعالیٰ کی رضا ہے نہ\\nاپنی مرضی اور اللہ تعالیٰ کی رضا فرمانبرداری میں ہے جو حکم وہ دے اس کی اطاعت کی جاوے اور\\nاپنی طرف سے اس پر حاشیہ نہ چڑھایا جاوے۔اس نے تو یہی حکم دیا ہے مَنْ كَانَ مِنْكُمُ\\nمَّرِيضًا أَوْ عَلى سَفَرٍ فَعِدَّةٌ مِّنْ أَيَّامٍ أُخَرُ (البقره: 185) اس میں کوئی قید اور نہیں لگائی کہ\\nایسا سفر ہو یا ایسی بیماری ہو۔میں سفر کی حالت میں روزہ نہیں رکھتا اور ایسا ہی بیماری کی حالت\\nمیں۔چنانچہ آج بھی میری طبیعت اچھی نہیں اور میں نے روزہ نہیں رکھا۔چلنے پھرنے سے\\nبیماری میں کچھ کمی ہوتی ہے اس لئے باہر جاؤں گا۔کیا آپ بھی چلیں گے۔با با چٹو : نہیں میں تو نہیں جاسکتا۔آپ ہو آئیں۔یہ حکم تو بے شک ہے مگر سفر میں کوئی\\nتکلیف نہیں پھر کیوں روزہ نہ رکھا جاوے۔حضرت اقدس:۔یہ تو آپ کی اپنی رائے ہے۔قرآن شریف نے تو تکلیف یا عدم تکلیف کا\\nکوئی ذکر نہیں فرمایا اب آپ بہت بوڑھے ہو گئے ہیں۔زندگی کا اعتبار کچھ نہیں۔انسان کو وہ راہ\\nاختیار کرنی چاہئے جس سے اللہ تعالیٰ راضی ہو جاوے اور صراط مستقیم مل جاوے۔بابا چٹو :۔میں تو اسی لئے آیا ہوں کہ آپ سے کچھ فائدہ اٹھاؤں۔اگر یہی راہ کچی ہے تو ایسانہ\\nہو کہ ہم غفلت ہی میں مر جاویں۔'), Document(id='827f2054-75e5-4466-a3e9-ab377cecc538', metadata={'chunk_index': 276.0, 'page': '219', 'title': 'fiqh-ul-masih'}, page_content='فقه المسيح، صفحہ 219\\nروزہ اور رمضان\\nتو بیٹھ کر ہی پڑھ لے اور بیٹھ کر نہ پڑھ سکے تو لیٹ کر پڑھ لے یا جس طرح کسی شخص کے\\nکپڑے کو غلاظت لگی ہو اور وہ اسے دھو نہ سکے تو اسی طرح نماز پڑھ لے، یہ کوئی مسئلہ نہیں\\nبلکہ ضرورت کی بات ہے۔بے خبری میں کھانے پینے سے روزہ نہیں ٹوٹتا\\nالفضل 21 فروری 1930 صفحه (12)\\nخط سے سوال پیش ہوا کہ میں بوقتِ سحر بماہ رمضان اندر بیٹھا ہوا بے خبری سے کھاتا پیتا رہا۔جب باہر نکل کر دیکھا تو معلوم ہوا کہ سفیدی ظاہر ہوگئی ہے۔کیا وہ روزہ میرے اوپر رکھنا لازم\\nہے یا نہیں؟ فرمایا:\\n” بے خبری میں کھایا پیا تو اس پر اس روزہ کے بدلہ میں دوسرا روزہ لازم نہیں آتا۔“\\nرسول اللہ ﷺ کے وصال کے دن روزہ رکھنا\\nالحکم 24 فروری 1907 صفحہ 14 )\\nسوال : کیا آنحضرت کے وصال کے دن روزہ رکھنا ضروری ہے کہ نہیں ؟ فرمایا:\\n66\\nضروری نہیں۔“\\nکیا محرم کے روزے ضروری ہیں؟\\n( بدر 14 مارچ 1907 ء صفحہ 5)\\nسوال پیش ہوا کہ محرم کے پہلے دس دن کا روزہ رکھنا ضروری ہے کہ نہیں ؟ فرمایا:\\nاعتکاف\\nضروری نہیں ہے۔“\\n( بدر 14 مارچ 1907 ، صفحہ 5)\\nحضرت صاحبزادہ مرزا بشیر احمد صاحب تحریر کرتے ہیں کہ مجھ سے حضرت والدہ صاحبہ نے\\nبیان کیا کہ میں نے کبھی حضرت مسیح موعود کو اعتکاف بیٹھتے نہیں دیکھا۔خاکسار عرض کرتا ہے کہ'), Document(id='3d7618e2-86b0-4a03-9c2f-6bc94397e500', metadata={'chunk_index': 265.0, 'page': '208', 'title': 'fiqh-ul-masih'}, page_content='فقه المسيح، صفحہ 208\\nروزہ اور رمضان\\nلگے رہے۔اس کھانے میں عمدہ سالن اور دودھ سویاں وغیرہ کھانے بھی تھے۔(سیرت المہدی جلد 2 صفحہ 203،202)\\nحضرت سید محمد سرور شاہ صاحب تحریر فرماتے ہیں:\\nروزوں کی بابت حضرت مسیح موعود علیہ السلام نے فرمایا ہے کہ اگر کسی شخص نے ایک جگہ\\nپر تین دن سے زائدا قامت کرنی ہو تو پھر وہ روزے رکھے اور اگر تین دن سے کم اقامت کرنی\\nہو تو روزے نہ رکھے اور اگر قادیان میں کم دن ٹھہرنے کے باوجود روزے رکھ لے تو پھر روزے\\nدوبارہ رکھنے کی ضرورت نہیں۔(فتاوی حضرت سید محمد سرور شاہ صاحب رجسٹر نمبر 5 دارالافتاء ربوہ )\\nبیمار ہونے پر روزہ کھول دیتا\\nحضرت صاحبزادہ مرزا بشیر احمد صاحب تحریر کرتے ہیں کہ ڈاکٹر میر محمد اسماعیل صاحب\\nنے مجھ سے بیان کیا کہ ایک دفعہ لدھیانہ میں حضرت مسیح موعود علیہ السلام نے رمضان کا\\nروزہ رکھا ہوا تھا کہ دل گھٹنے کا دورہ ہوا اور ہاتھ پاؤں ٹھنڈے ہو گئے۔اس وقت غروب\\nآفتاب کا وقت بہت قریب تھا مگر آپ نے فورا روزہ تو ڑ دیا۔آپ ہمیشہ شریعت میں سہل\\nراستہ کو اختیار فرمایا کرتے تھے۔خاکسار عرض کرتا ہے کہ حدیث میں حضرت عائشہؓ کی روایت سے آنحضرت صلی اللہ\\nعلیہ وسلم کے متعلق بھی یہی ذکر آتا ہے کہ آپ ہمیشہ دو جائز رستوں میں سے سہل رستہ کو پسند\\nفرماتے تھے۔(سیرت المہدی جلد 1 صفحہ 637)\\nمعمولی بیماری میں روزہ رکھنے کی اجازت\\nحضرت منشی حبیب الرحمن صاحب لکھتے ہیں:\\nایک دفعہ میں نے رمضان شریف کا آخری عشرہ قادیان میں گذارا۔ان دنوں میں حضور\\nعلیہ السلام کو تپ لرزہ یومیہ آتا تھا۔ظہر کے بعد لرزہ سے تپ ہو جاتا تھا۔اس لئے ظہر کے وقت\\nحضور جماعت میں شریک ہوا کرتے تھے اور باقی نمازوں میں شریک نہیں ہو سکتے تھے۔ظہر سے')]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'اللہ تعالیٰ نے اپنے بندوں پر کوئی تنگی نہیں ڈالی، اور دینِ اسلام میں آسانی اور سہولت کا پہلو نمایاں ہے۔ روزے چھوڑنا بعض حالات میں نہ صرف جائز ہے بلکہ بعض اوقات رخصت پر عمل کرنا ہی تقویٰ کہلاتا ہے۔\\n\\nمندرجہ ذیل حالات میں روزے چھوڑنا جائز ہے:\\n\\n1.  **بیماری:** اگر کوئی شخص بیمار ہو تو اس کے لیے روزہ چھوڑنا جائز ہے۔ حضرت اقدس مسیح موعود علیہ السلام نے فرمایا ہے کہ اللہ تعالیٰ نے مسافر اور بیمار کو دوسرے وقت روزہ رکھنے کی اجازت اور رخصت دی ہے، اس لیے اس حکم پر بھی عمل کرنا چاہیے۔ آپؑ نے یہ بھی فرمایا کہ قرآن شریف کی رخصتوں پر عمل کرنا بھی تقویٰ ہے، اور بعض اکابر اس طرف گئے ہیں کہ اگر کوئی حالتِ بیماری میں روزہ رکھتا ہے تو یہ معصیت ہے۔ خود حضرت مسیح موعود علیہ السلام نے بیماری کی حالت میں روزہ نہیں رکھا۔\\n    *   **حوالہ:** فقہ المسیح، صفحہ 200\\n    *   حضرت مسیح موعود علیہ السلام کے متعلق بیان کیا گیا ہے کہ ایک دفعہ لدھیانہ میں رمضان کا روزہ رکھا ہوا تھا کہ دل گھٹنے کا دورہ ہوا اور ہاتھ پاؤں ٹھنڈے ہو گئے، اس وقت غروب آفتاب کا وقت بہت قریب تھا مگر آپؑ نے فوراً روزہ توڑ دیا۔ آپؑ ہمیشہ شریعت میں سہل راستہ کو اختیار فرمایا کرتے تھے۔\\n    *   **حوالہ:** فقہ المسیح، صفحہ 208؛ سیرت المہدی جلد 1 صفحہ 637\\n\\n2.  **سفر:** مسافر کے لیے بھی روزہ چھوڑنا جائز ہے۔ حضرت مسیح موعود علیہ السلام نے فرمایا کہ اگر کسی شخص نے ایک جگہ پر تین دن سے زائد اقامت کرنی ہو تو پھر وہ روزے رکھے، اور اگر تین دن سے کم اقامت کرنی ہو تو روزے نہ رکھے (البتہ اگر قادیان میں کم دن ٹھہرنے کے باوجود روزے رکھ لے تو پھر روزے دوبارہ رکھنے کی ضرورت نہیں)۔ حضرت مسیح موعود علیہ السلام خود سفر کی حالت میں روزہ نہیں رکھتے تھے اور اس پر عمل کو تقویٰ قرار دیتے تھے۔\\n    *   **حوالہ:** فقہ المسیح، صفحہ 200، 208 (فتاوی حضرت سید محمد سرور شاہ صاحب رجسٹر نمبر 5 دارالافتاء ربوہ)\\n\\n3.  **بے خبری میں کھانے پینے سے:** اگر کوئی شخص رمضان میں سحری کے وقت بے خبری میں کھاتا پیتا رہے اور بعد میں معلوم ہو کہ سفیدی (صبح صادق) ظاہر ہو چکی ہے، تو اس پر اس روزہ کے بدلہ میں دوسرا روزہ لازم نہیں آتا، یعنی وہ روزہ نہیں ٹوٹتا۔ یہ اگرچہ روزہ چھوڑنے کی صورت نہیں بلکہ بے خبری میں کھانے پینے کا حکم ہے، تاہم یہ سہولت کا ایک پہلو ہے۔\\n    *   **حوالہ:** فقہ المسیح، صفحہ 219؛ الفضل 21 فروری 1930 صفحہ 12\\n\\n4.  **غیر ضروری روزے:** بعض روزے ایسے ہیں جو شرعاً فرض یا ضروری نہیں ہوتے، ان کو چھوڑنا جائز ہے کیونکہ وہ لازم ہی نہیں۔ مثلاً:\\n    *   آنحضرت ﷺ کے وصال کے دن روزہ رکھنا ضروری نہیں۔\\n    *   محرم کے پہلے دس دن کا روزہ رکھنا ضروری نہیں۔\\n    *   **حوالہ:** فقہ المسیح، صفحہ 219؛ الحکم 24 فروری 1907 صفحہ 14؛ بدر 14 مارچ 1907 صفحہ 5\\n\\nخلاصہ کلام یہ کہ شریعت نے بیمار اور مسافر کو روزہ چھوڑنے کی رخصت دی ہے، اور اس رخصت پر عمل کرنا نہ صرف جائز ہے بلکہ بعض اوقات اس میں اللہ تعالیٰ کی رضا اور تقویٰ کا اظہار ہوتا ہے۔ رسول اللہ ﷺ اور حضرت مسیح موعود علیہ السلام نے ہمیشہ شریعت میں سہل راستہ کو پسند فرمایا ہے۔'"
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_chain.invoke(\"rozay chorna jaiz hai?\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Gemini_LangChain_QA_Pinecone_WebLoad.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
